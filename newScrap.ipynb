{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73bf4db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dd988e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#eval_df = pd.read_csv('/ceph/dpandya/notsofar/nsfd_adap_segments/adapter_base/large/eval_seqBN_r4full_ds_.csv')\n",
    "eval_df = pd.read_csv('/ceph/dpandya/notsofar/nsfd_adap_segments/adapter_base/large/eval_parBN_r4full_ds_5e_.csv')\n",
    "eval_df = eval_df.sort_values(by='wer', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d00d691c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5522355068363344"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df['wer'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "24ad779b",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = eval_df[eval_df.columns[-2]]\n",
    "truth = eval_df[eval_df.columns[-3]]\n",
    "wer = eval_df[eval_df.columns[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2b3723a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'And theyre unhappy about it And uh no So come uh you come with solutions you know what we come with a problem and you can come maybe come back and then well FILLlaugh consider your solutions What do you expect Mmhmm I mean you have a adjacents I mean weve had uh since the day of the elections weve had uh since the day of the elections weve had uh since the day of the elections weve had uh since the day of the elections weve had uh since the day of the elections weve had uh since the day of the elections weve had uh since the day of the elections weve had uh since the day of the elections weve had uh since the day of the elections weve had uh since the day of the elections weve had uh since the day of the elections weve had uh since the day of the elections weve had uh since the day of the elections weve had uh since the day of the elections weve had uh since the day of the elections weve had uh since the day of the elections weve had uh since the day of the elections weve had uh since the day of the elections weve had uh since the day of the elections weve had uh since the day of the elections weve had uh since the day of the elections weve had uh since the day of the elections weve had uh since the day of the elections weve had weve sensed that sort of the elections So comeançaisSTlaugh I mean you know we can maybe come with a good idea I mean you know we will consider your solutions to make it I mean you have a good idea'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5cb6dc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df['audio'] = eval_df['segmented_audio_file']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b922e5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df['preds'] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5b3ce857",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'And theyre unhappy about it And uh no So come uh you come with solutions you know what we come with a problem and you can come maybe come back and then well FILLlaugh consider your solutions What do you expect Mmhmm I mean you have a adjacents I mean weve had uh since the day of the elections weve had uh since the day of the elections weve had uh since the day of the elections weve had uh since the day of the elections weve had uh since the day of the elections weve had uh since the day of the elections weve had uh since the day of the elections weve had uh since the day of the elections weve had uh since the day of the elections weve had uh since the day of the elections weve had uh since the day of the elections weve had uh since the day of the elections weve had uh since the day of the elections weve had uh since the day of the elections weve had uh since the day of the elections weve had uh since the day of the elections weve had uh since the day of the elections weve had uh since the day of the elections weve had uh since the day of the elections weve had uh since the day of the elections weve had uh since the day of the elections weve had uh since the day of the elections weve had uh since the day of the elections weve had weve sensed that sort of the elections So comeançaisSTlaugh I mean you know we can maybe come with a good idea I mean you know we will consider your solutions to make it I mean you have a good idea'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df['preds'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cf142d29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There are adapters available but none are activated for the forward pass.\n"
     ]
    }
   ],
   "source": [
    "from transformers import WhisperForConditionalGeneration\n",
    "import adapters\n",
    "\n",
    "whisper_model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-large-v3\")\n",
    "\n",
    "whisper_adapter = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-large-v3\")\n",
    "adapters.init(whisper_adapter)\n",
    "adapter_name = whisper_adapter.load_adapter('/ceph/dpandya/notsofar/nsfd_adap_segments/adapter_base/large/full_ds/parBN_r4full_ds_5e')\n",
    "whisper_adapter.set_active_adapters(adapter_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9566f419",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_files = eval_df['segmented_audio_file']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6dcb593a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutomaticSpeechRecognitionPipeline\n",
    "from transformers import WhisperProcessor\n",
    "\n",
    "processor = WhisperProcessor.from_pretrained('openai/whisper-large-v3', language=\"english\", task=\"transcribe\")\n",
    "eval_pipeline = AutomaticSpeechRecognitionPipeline(\n",
    "            model=whisper_model,\n",
    "            feature_extractor=processor.feature_extractor,\n",
    "            tokenizer=processor.tokenizer,\n",
    "            device=\"cuda:0\", # Use GPU 0, or -1 for CPU\n",
    "            chunk_length_s=30\n",
    "        )\n",
    "\n",
    "eval_adap_pipeline = AutomaticSpeechRecognitionPipeline(\n",
    "            model=whisper_adapter,\n",
    "            feature_extractor=processor.feature_extractor,\n",
    "            tokenizer=processor.tokenizer,\n",
    "            device=\"cuda:0\", # Use GPU 0, or -1 for CPU\n",
    "            chunk_length_s=30\n",
    "        )\n",
    "\n",
    "forced_decoder_ids = processor.get_decoder_prompt_ids(language=\"english\", task=\"transcribe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "68757fd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/dpandya/miniconda3/envs/onlyWhisper/lib/python3.11/site-packages/transformers/models/whisper/generation_whisper.py:573: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "i = 3\n",
    "pred = eval_pipeline(eval_df['audio'].iloc[i], \n",
    "              generate_kwargs = {'forced_decoder_ids': forced_decoder_ids,\n",
    "                                 \"temperature\": 0.0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "773916da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/dpandya/miniconda3/envs/onlyWhisper/lib/python3.11/site-packages/transformers/models/whisper/generation_whisper.py:573: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "pred_adapter = eval_adap_pipeline(eval_df['audio'].iloc[i], \n",
    "              generate_kwargs = {'forced_decoder_ids': forced_decoder_ids,\n",
    "                                 \"temperature\": 0.0,\n",
    "                                 \"no_repeat_ngram_size\": 4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "88ed0438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22058823529411764 0.4117647058823529\n"
     ]
    }
   ],
   "source": [
    "import jiwer\n",
    "import eval_utils as eu\n",
    "\n",
    "print(jiwer.wer(hypothesis=eu.clean_text(pred['text']), truth=eu.clean_text(eval_df[\"transcription\"].iloc[i])), \n",
    "      jiwer.wer(hypothesis=eu.clean_text(pred_adapter['text']), truth=eu.clean_text(eval_df[\"transcription\"].iloc[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5b401a4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('are they fine are they okay theyre great no no we didnt get much further ahead nothing substantial just discussing cats cats and dogs yeah okay so what i want to know is okay the company were renting the van from why are we renting well',\n",
       " 'are they fine are they ok they can be graved ok thats it no no no we didnt get much further ahead no no we didnt give them much further ahead we were just discussing cats yeah um cats and dogs yeah ok so what iststst ststlaughs what i want to ststst what i want to know is um ok the stst laughs the company the filllaughs the company we were renting the van from why are we renting um well',\n",
       " 'everything fine everything ok great no no uh no no we didnt get much further ahead nothing substantial yeah were just discussing cats um cats and dogs yeah ok so what i what i want to know is um ok the the the company uh the company we were renting the van from why are we renting uh well')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eu.clean_text(pred['text']), eu.clean_text(pred_adapter['text']), eu.clean_text(eval_df[\"transcription\"].iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "85010522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Well I love what that sounds like but Im not sure that it would be practical for us to go that far So Ive put it into a different frame And Ive got the graphs for that Ill share that with you next week So that everyone can see how its impacting the overall business and the projected budgets for next year and for the year after',\n",
       " 0.0149253731343283)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df['preds_text_seqBN_r4full_ds_5e'].iloc[i], eval_df['wer'].iloc[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "a56d225c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4852944095193342"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('/ceph/dpandya/notsofar/nsfd_adap_segments/adapter_base/large/eval_seqBN_r4full_ds_.csv')['wer'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "8049de2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output_dir': '/ceph/dpandya/notsofar/nsfd_adap_segments/adapter_base/large/full_ds/seqBN_r4full_ds',\n",
       " 'overwrite_output_dir': False,\n",
       " 'do_train': False,\n",
       " 'do_eval': True,\n",
       " 'do_predict': False,\n",
       " 'eval_strategy': 'epoch',\n",
       " 'prediction_loss_only': False,\n",
       " 'per_device_train_batch_size': 4,\n",
       " 'per_device_eval_batch_size': 8,\n",
       " 'per_gpu_train_batch_size': None,\n",
       " 'per_gpu_eval_batch_size': None,\n",
       " 'gradient_accumulation_steps': 2,\n",
       " 'eval_accumulation_steps': None,\n",
       " 'eval_delay': 0,\n",
       " 'torch_empty_cache_steps': None,\n",
       " 'learning_rate': 0.0005,\n",
       " 'weight_decay': 0.0,\n",
       " 'adam_beta1': 0.9,\n",
       " 'adam_beta2': 0.999,\n",
       " 'adam_epsilon': 1e-08,\n",
       " 'max_grad_norm': 1.0,\n",
       " 'num_train_epochs': 10,\n",
       " 'max_steps': -1,\n",
       " 'lr_scheduler_type': 'linear',\n",
       " 'lr_scheduler_kwargs': {},\n",
       " 'warmup_ratio': 0.1,\n",
       " 'warmup_steps': 0,\n",
       " 'log_level': 'passive',\n",
       " 'log_level_replica': 'warning',\n",
       " 'log_on_each_node': True,\n",
       " 'logging_dir': '/ceph/dpandya/notsofar/nsfd_adap_segments/adapter_base/large/full_ds/seqBN_r4full_ds/runs/Nov12_20-09-13_dws-11.informatik.uni-mannheim.de',\n",
       " 'logging_strategy': 'steps',\n",
       " 'logging_first_step': False,\n",
       " 'logging_steps': 50,\n",
       " 'logging_nan_inf_filter': True,\n",
       " 'save_strategy': 'epoch',\n",
       " 'save_steps': 500,\n",
       " 'save_total_limit': 2,\n",
       " 'save_safetensors': True,\n",
       " 'save_on_each_node': False,\n",
       " 'save_only_model': False,\n",
       " 'restore_callback_states_from_checkpoint': False,\n",
       " 'no_cuda': False,\n",
       " 'use_cpu': False,\n",
       " 'use_mps_device': False,\n",
       " 'seed': 42,\n",
       " 'data_seed': None,\n",
       " 'jit_mode_eval': False,\n",
       " 'use_ipex': False,\n",
       " 'bf16': False,\n",
       " 'fp16': True,\n",
       " 'fp16_opt_level': 'O1',\n",
       " 'half_precision_backend': 'auto',\n",
       " 'bf16_full_eval': False,\n",
       " 'fp16_full_eval': False,\n",
       " 'tf32': None,\n",
       " 'local_rank': 0,\n",
       " 'ddp_backend': None,\n",
       " 'tpu_num_cores': None,\n",
       " 'tpu_metrics_debug': False,\n",
       " 'debug': [],\n",
       " 'dataloader_drop_last': False,\n",
       " 'eval_steps': None,\n",
       " 'dataloader_num_workers': 0,\n",
       " 'dataloader_prefetch_factor': None,\n",
       " 'past_index': -1,\n",
       " 'run_name': '/ceph/dpandya/notsofar/nsfd_adap_segments/adapter_base/large/full_ds/seqBN_r4full_ds',\n",
       " 'disable_tqdm': False,\n",
       " 'remove_unused_columns': False,\n",
       " 'label_names': ['labels'],\n",
       " 'load_best_model_at_end': True,\n",
       " 'metric_for_best_model': 'wer',\n",
       " 'greater_is_better': False,\n",
       " 'ignore_data_skip': False,\n",
       " 'fsdp': [],\n",
       " 'fsdp_min_num_params': 0,\n",
       " 'fsdp_config': {'min_num_params': 0,\n",
       "  'xla': False,\n",
       "  'xla_fsdp_v2': False,\n",
       "  'xla_fsdp_grad_ckpt': False},\n",
       " 'tp_size': 0,\n",
       " 'fsdp_transformer_layer_cls_to_wrap': None,\n",
       " 'accelerator_config': {'split_batches': False,\n",
       "  'dispatch_batches': None,\n",
       "  'even_batches': True,\n",
       "  'use_seedable_sampler': True,\n",
       "  'non_blocking': False,\n",
       "  'gradient_accumulation_kwargs': None},\n",
       " 'deepspeed': None,\n",
       " 'label_smoothing_factor': 0.0,\n",
       " 'optim': 'adamw_torch',\n",
       " 'optim_args': None,\n",
       " 'adafactor': False,\n",
       " 'group_by_length': False,\n",
       " 'length_column_name': 'length',\n",
       " 'report_to': ['tensorboard'],\n",
       " 'ddp_find_unused_parameters': None,\n",
       " 'ddp_bucket_cap_mb': None,\n",
       " 'ddp_broadcast_buffers': None,\n",
       " 'dataloader_pin_memory': True,\n",
       " 'dataloader_persistent_workers': False,\n",
       " 'skip_memory_metrics': True,\n",
       " 'use_legacy_prediction_loop': False,\n",
       " 'push_to_hub': False,\n",
       " 'resume_from_checkpoint': None,\n",
       " 'hub_model_id': None,\n",
       " 'hub_strategy': 'every_save',\n",
       " 'hub_token': '<HUB_TOKEN>',\n",
       " 'hub_private_repo': None,\n",
       " 'hub_always_push': False,\n",
       " 'gradient_checkpointing': False,\n",
       " 'gradient_checkpointing_kwargs': None,\n",
       " 'include_inputs_for_metrics': False,\n",
       " 'include_for_metrics': [],\n",
       " 'eval_do_concat_batches': True,\n",
       " 'fp16_backend': 'auto',\n",
       " 'push_to_hub_model_id': None,\n",
       " 'push_to_hub_organization': None,\n",
       " 'push_to_hub_token': '<PUSH_TO_HUB_TOKEN>',\n",
       " 'mp_parameters': '',\n",
       " 'auto_find_batch_size': False,\n",
       " 'full_determinism': False,\n",
       " 'torchdynamo': None,\n",
       " 'ray_scope': 'last',\n",
       " 'ddp_timeout': 1800,\n",
       " 'torch_compile': False,\n",
       " 'torch_compile_backend': None,\n",
       " 'torch_compile_mode': None,\n",
       " 'include_tokens_per_second': False,\n",
       " 'include_num_input_tokens_seen': False,\n",
       " 'neftune_noise_alpha': None,\n",
       " 'optim_target_modules': None,\n",
       " 'batch_eval_metrics': False,\n",
       " 'eval_on_start': False,\n",
       " 'use_liger_kernel': False,\n",
       " 'eval_use_gather_object': False,\n",
       " 'average_tokens_across_devices': False}"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('/ceph/dpandya/notsofar/nsfd_adap_segments/adapter_base/large/full_ds/seqBN_r4full_ds/training_args.json', 'r') as f:\n",
    "    tr_args = json.load(f)\n",
    "\n",
    "tr_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f386e32f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10756"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir('/ceph/dpandya/notsofar/train_set/240825.1_train/new_segmented_audios/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8157d98c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sc_files</th>\n",
       "      <th>gt_transcription_files</th>\n",
       "      <th>mic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>plaza_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>rockfall_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>meetup_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>rockfall_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>rockfall_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>plaza_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>rockfall_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>meetup_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>rockfall_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>rockfall_0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>346 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              sc_files  \\\n",
       "0    /ceph/dpandya/notsofar/train_set/240825.1_trai...   \n",
       "1    /ceph/dpandya/notsofar/train_set/240825.1_trai...   \n",
       "2    /ceph/dpandya/notsofar/train_set/240825.1_trai...   \n",
       "3    /ceph/dpandya/notsofar/train_set/240825.1_trai...   \n",
       "4    /ceph/dpandya/notsofar/train_set/240825.1_trai...   \n",
       "..                                                 ...   \n",
       "341  /ceph/dpandya/notsofar/train_set/240825.1_trai...   \n",
       "342  /ceph/dpandya/notsofar/train_set/240825.1_trai...   \n",
       "343  /ceph/dpandya/notsofar/train_set/240825.1_trai...   \n",
       "344  /ceph/dpandya/notsofar/train_set/240825.1_trai...   \n",
       "345  /ceph/dpandya/notsofar/train_set/240825.1_trai...   \n",
       "\n",
       "                                gt_transcription_files         mic  \n",
       "0    /ceph/dpandya/notsofar/train_set/240825.1_trai...     plaza_0  \n",
       "1    /ceph/dpandya/notsofar/train_set/240825.1_trai...  rockfall_2  \n",
       "2    /ceph/dpandya/notsofar/train_set/240825.1_trai...    meetup_0  \n",
       "3    /ceph/dpandya/notsofar/train_set/240825.1_trai...  rockfall_1  \n",
       "4    /ceph/dpandya/notsofar/train_set/240825.1_trai...  rockfall_0  \n",
       "..                                                 ...         ...  \n",
       "341  /ceph/dpandya/notsofar/train_set/240825.1_trai...     plaza_0  \n",
       "342  /ceph/dpandya/notsofar/train_set/240825.1_trai...  rockfall_2  \n",
       "343  /ceph/dpandya/notsofar/train_set/240825.1_trai...    meetup_0  \n",
       "344  /ceph/dpandya/notsofar/train_set/240825.1_trai...  rockfall_1  \n",
       "345  /ceph/dpandya/notsofar/train_set/240825.1_trai...  rockfall_0  \n",
       "\n",
       "[346 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('/ceph/dpandya/notsofar/train_set/240825.1_train/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c3756937",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.088404663923182"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_train = pd.read_csv('/ceph/dpandya/notsofar/nsfd_adap_segments/new_train_segments.csv')\n",
    "current_train['dur'] = current_train['stop']-current_train['start']\n",
    "current_train['dur'].mean()/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "20c3eef7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.92064"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(current_train)*17.088)/3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2de92f9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>org_audio_file</th>\n",
       "      <th>segmented_audio_file</th>\n",
       "      <th>text</th>\n",
       "      <th>prediction_large_seqBN_5e</th>\n",
       "      <th>wer_seqBN_5e</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/ceph/dpandya/notsofar/dev_set/240825.1_dev1/M...</td>\n",
       "      <td>/ceph/dpandya/notsofar/dev_set/240825.1_dev1/n...</td>\n",
       "      <td>ok so were designing todays hackathon uhhuh ye...</td>\n",
       "      <td>ok so were designing todays hackathon uhhuh er...</td>\n",
       "      <td>0.160714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/ceph/dpandya/notsofar/dev_set/240825.1_dev1/M...</td>\n",
       "      <td>/ceph/dpandya/notsofar/dev_set/240825.1_dev1/n...</td>\n",
       "      <td>we obey with that it was obvious she made a mi...</td>\n",
       "      <td>but it was it was obvious she made a mistake i...</td>\n",
       "      <td>0.370787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/ceph/dpandya/notsofar/dev_set/240825.1_dev1/M...</td>\n",
       "      <td>/ceph/dpandya/notsofar/dev_set/240825.1_dev1/n...</td>\n",
       "      <td>everybody is getting together and i mean every...</td>\n",
       "      <td>and everybody is getting together and i mean e...</td>\n",
       "      <td>0.096154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/ceph/dpandya/notsofar/dev_set/240825.1_dev1/M...</td>\n",
       "      <td>/ceph/dpandya/notsofar/dev_set/240825.1_dev1/n...</td>\n",
       "      <td>if we win yeah then we get the trip that big t...</td>\n",
       "      <td>if we win yeah then we get the trip the big tr...</td>\n",
       "      <td>0.441558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/ceph/dpandya/notsofar/dev_set/240825.1_dev1/M...</td>\n",
       "      <td>/ceph/dpandya/notsofar/dev_set/240825.1_dev1/n...</td>\n",
       "      <td>this is like basically make food better techno...</td>\n",
       "      <td>this is like basic make food better technology...</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3468</th>\n",
       "      <td>/ceph/dpandya/notsofar/dev_set/240825.1_dev1/M...</td>\n",
       "      <td>/ceph/dpandya/notsofar/dev_set/240825.1_dev1/n...</td>\n",
       "      <td>precise perspective and not look about the ext...</td>\n",
       "      <td>precise perspective and not look about the ext...</td>\n",
       "      <td>0.132353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3469</th>\n",
       "      <td>/ceph/dpandya/notsofar/dev_set/240825.1_dev1/M...</td>\n",
       "      <td>/ceph/dpandya/notsofar/dev_set/240825.1_dev1/n...</td>\n",
       "      <td>yeah and when you look at the the atmosphere i...</td>\n",
       "      <td>yeah when you look at the the atmosphere in ve...</td>\n",
       "      <td>0.169014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3470</th>\n",
       "      <td>/ceph/dpandya/notsofar/dev_set/240825.1_dev1/M...</td>\n",
       "      <td>/ceph/dpandya/notsofar/dev_set/240825.1_dev1/n...</td>\n",
       "      <td>yeah well i mean venus has the same gravity as...</td>\n",
       "      <td>yeah well i mean venus is the same gravity as ...</td>\n",
       "      <td>0.282051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3471</th>\n",
       "      <td>/ceph/dpandya/notsofar/dev_set/240825.1_dev1/M...</td>\n",
       "      <td>/ceph/dpandya/notsofar/dev_set/240825.1_dev1/n...</td>\n",
       "      <td>we can work we we need greenhouses in both pla...</td>\n",
       "      <td>we can work we would need greenhouses in both ...</td>\n",
       "      <td>0.282051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3472</th>\n",
       "      <td>/ceph/dpandya/notsofar/dev_set/240825.1_dev1/M...</td>\n",
       "      <td>/ceph/dpandya/notsofar/dev_set/240825.1_dev1/n...</td>\n",
       "      <td>uh i think i might be a problem ok ok yeah you...</td>\n",
       "      <td>uh i think that might be a problem we might ha...</td>\n",
       "      <td>0.493827</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3473 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         org_audio_file  \\\n",
       "0     /ceph/dpandya/notsofar/dev_set/240825.1_dev1/M...   \n",
       "1     /ceph/dpandya/notsofar/dev_set/240825.1_dev1/M...   \n",
       "2     /ceph/dpandya/notsofar/dev_set/240825.1_dev1/M...   \n",
       "3     /ceph/dpandya/notsofar/dev_set/240825.1_dev1/M...   \n",
       "4     /ceph/dpandya/notsofar/dev_set/240825.1_dev1/M...   \n",
       "...                                                 ...   \n",
       "3468  /ceph/dpandya/notsofar/dev_set/240825.1_dev1/M...   \n",
       "3469  /ceph/dpandya/notsofar/dev_set/240825.1_dev1/M...   \n",
       "3470  /ceph/dpandya/notsofar/dev_set/240825.1_dev1/M...   \n",
       "3471  /ceph/dpandya/notsofar/dev_set/240825.1_dev1/M...   \n",
       "3472  /ceph/dpandya/notsofar/dev_set/240825.1_dev1/M...   \n",
       "\n",
       "                                   segmented_audio_file  \\\n",
       "0     /ceph/dpandya/notsofar/dev_set/240825.1_dev1/n...   \n",
       "1     /ceph/dpandya/notsofar/dev_set/240825.1_dev1/n...   \n",
       "2     /ceph/dpandya/notsofar/dev_set/240825.1_dev1/n...   \n",
       "3     /ceph/dpandya/notsofar/dev_set/240825.1_dev1/n...   \n",
       "4     /ceph/dpandya/notsofar/dev_set/240825.1_dev1/n...   \n",
       "...                                                 ...   \n",
       "3468  /ceph/dpandya/notsofar/dev_set/240825.1_dev1/n...   \n",
       "3469  /ceph/dpandya/notsofar/dev_set/240825.1_dev1/n...   \n",
       "3470  /ceph/dpandya/notsofar/dev_set/240825.1_dev1/n...   \n",
       "3471  /ceph/dpandya/notsofar/dev_set/240825.1_dev1/n...   \n",
       "3472  /ceph/dpandya/notsofar/dev_set/240825.1_dev1/n...   \n",
       "\n",
       "                                                   text  \\\n",
       "0     ok so were designing todays hackathon uhhuh ye...   \n",
       "1     we obey with that it was obvious she made a mi...   \n",
       "2     everybody is getting together and i mean every...   \n",
       "3     if we win yeah then we get the trip that big t...   \n",
       "4     this is like basically make food better techno...   \n",
       "...                                                 ...   \n",
       "3468  precise perspective and not look about the ext...   \n",
       "3469  yeah and when you look at the the atmosphere i...   \n",
       "3470  yeah well i mean venus has the same gravity as...   \n",
       "3471  we can work we we need greenhouses in both pla...   \n",
       "3472  uh i think i might be a problem ok ok yeah you...   \n",
       "\n",
       "                              prediction_large_seqBN_5e  wer_seqBN_5e  \n",
       "0     ok so were designing todays hackathon uhhuh er...      0.160714  \n",
       "1     but it was it was obvious she made a mistake i...      0.370787  \n",
       "2     and everybody is getting together and i mean e...      0.096154  \n",
       "3     if we win yeah then we get the trip the big tr...      0.441558  \n",
       "4     this is like basic make food better technology...      0.600000  \n",
       "...                                                 ...           ...  \n",
       "3468  precise perspective and not look about the ext...      0.132353  \n",
       "3469  yeah when you look at the the atmosphere in ve...      0.169014  \n",
       "3470  yeah well i mean venus is the same gravity as ...      0.282051  \n",
       "3471  we can work we would need greenhouses in both ...      0.282051  \n",
       "3472  uh i think that might be a problem we might ha...      0.493827  \n",
       "\n",
       "[3473 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('/ceph/dpandya/notsofar/newSegments_adap/large/RF4/large_seqBN_5e.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e00eeb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3607927237315797"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('/ceph/dpandya/notsofar/newSegments_adap/large/RF4/large_seqBN_5e.csv')['wer_seqBN_5e'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8a93e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>org_audio_file</th>\n",
       "      <th>segmented_audio_file</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>alright everyone let us continue on with our ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>have any of you guys used it yet? um not not y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>i would i would love to try it to see. but is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>so you don't have to have someone monitoring y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>oh i see, oh i see, ok. and you could just to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6776</th>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>i think both is is a good option. you think bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6777</th>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>there could be um like toys and things for kid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6778</th>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>what i feel wasn't set up an ice cream cone li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6779</th>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>maybe like each level like the first level is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6780</th>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>ice cream. most personalized ice cream. journe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6781 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         org_audio_file  \\\n",
       "0     /ceph/dpandya/notsofar/train_set/240825.1_trai...   \n",
       "1     /ceph/dpandya/notsofar/train_set/240825.1_trai...   \n",
       "2     /ceph/dpandya/notsofar/train_set/240825.1_trai...   \n",
       "3     /ceph/dpandya/notsofar/train_set/240825.1_trai...   \n",
       "4     /ceph/dpandya/notsofar/train_set/240825.1_trai...   \n",
       "...                                                 ...   \n",
       "6776  /ceph/dpandya/notsofar/train_set/240825.1_trai...   \n",
       "6777  /ceph/dpandya/notsofar/train_set/240825.1_trai...   \n",
       "6778  /ceph/dpandya/notsofar/train_set/240825.1_trai...   \n",
       "6779  /ceph/dpandya/notsofar/train_set/240825.1_trai...   \n",
       "6780  /ceph/dpandya/notsofar/train_set/240825.1_trai...   \n",
       "\n",
       "                                   segmented_audio_file  \\\n",
       "0     /ceph/dpandya/notsofar/train_set/240825.1_trai...   \n",
       "1     /ceph/dpandya/notsofar/train_set/240825.1_trai...   \n",
       "2     /ceph/dpandya/notsofar/train_set/240825.1_trai...   \n",
       "3     /ceph/dpandya/notsofar/train_set/240825.1_trai...   \n",
       "4     /ceph/dpandya/notsofar/train_set/240825.1_trai...   \n",
       "...                                                 ...   \n",
       "6776  /ceph/dpandya/notsofar/train_set/240825.1_trai...   \n",
       "6777  /ceph/dpandya/notsofar/train_set/240825.1_trai...   \n",
       "6778  /ceph/dpandya/notsofar/train_set/240825.1_trai...   \n",
       "6779  /ceph/dpandya/notsofar/train_set/240825.1_trai...   \n",
       "6780  /ceph/dpandya/notsofar/train_set/240825.1_trai...   \n",
       "\n",
       "                                                   text  \n",
       "0      alright everyone let us continue on with our ...  \n",
       "1     have any of you guys used it yet? um not not y...  \n",
       "2     i would i would love to try it to see. but is ...  \n",
       "3     so you don't have to have someone monitoring y...  \n",
       "4     oh i see, oh i see, ok. and you could just to ...  \n",
       "...                                                 ...  \n",
       "6776  i think both is is a good option. you think bo...  \n",
       "6777  there could be um like toys and things for kid...  \n",
       "6778  what i feel wasn't set up an ice cream cone li...  \n",
       "6779  maybe like each level like the first level is ...  \n",
       "6780  ice cream. most personalized ice cream. journe...  \n",
       "\n",
       "[6781 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pd.read_csv('/ceph/dpandya/notsofar/train_set/240825.1_train/train.csv')\n",
    "#pd.read_csv('/ceph/dpandya/notsofar/train_set/240825.1_train/segmented_audios.csv')\n",
    "pd.read_csv('/ceph/dpandya/notsofar/train_set/240825.1_train/new_segmented_audios/new_segmented_audios.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "onlyWhisper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

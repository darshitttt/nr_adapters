{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "231b7727",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/dpandya/miniconda3/envs/onlyWhisper/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from IPython.display import display, Audio\n",
    "import librosa\n",
    "import random\n",
    "import whisper\n",
    "import adapters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "30e64504",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"adapter_name = model.load_adapter(\\n    '/ceph/dpandya/notsofar/nsfd_adap_segments/adapter_base/medium/seqBN_r16/',\\n    set_active=True\\n)\\n#model.config.max_length=512\\nmodel.set_active_adapters(adapter_name)\""
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutomaticSpeechRecognitionPipeline\n",
    "from transformers import WhisperFeatureExtractor, WhisperTokenizer, pipeline, WhisperProcessor\n",
    "import torch\n",
    "\n",
    "model_name = 'openai/whisper-large-v3'\n",
    "\n",
    "feature_extractor = WhisperFeatureExtractor.from_pretrained(model_name, language=\"english\", task=\"transcribe\", sample_rate=16000)\n",
    "tokenizer = WhisperTokenizer.from_pretrained(model_name, language=\"english\", task=\"transcribe\")\n",
    "processor = WhisperProcessor.from_pretrained(model_name, language=\"english\", task=\"transcribe\")\n",
    "\n",
    "#model = adapters.WhisperAdapterModel.from_pretrained(model_name, language=\"english\", task=\"transcribe\")\n",
    "model = adapters.WhisperAdapterModel.from_pretrained(model_name)\n",
    "#model.config.max_length = 512\n",
    "#model.config.use_cache = False\n",
    "'''adapter_name = model.load_adapter(\n",
    "    '/ceph/dpandya/notsofar/nsfd_adap_segments/adapter_base/medium/seqBN_r16/',\n",
    "    set_active=True\n",
    ")\n",
    "#model.config.max_length=512\n",
    "model.set_active_adapters(adapter_name)'''\n",
    "#ddf = pd.read_csv('/ceph/dpandya/notsofar/nsfd_adap_segments/adapter_base/medium/eval_seqBN_r8.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e2b66687",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.generation_config._from_model_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1116d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''model.config.forced_decoder_ids = None\n",
    "model.config.suppress_tokens = []\n",
    "model.generation_config.forced_decoder_ids = None\n",
    "model.generation_config._from_model_config = True'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0294b540",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.generation_config.input_ids = model.generation_config.forced_decoder_ids\n",
    "model.generation_config.forced_decoder_ids = None\n",
    "model.generation_config.alignment_heads = [[2, 2], [3, 0], [3, 2], [3, 3], [3, 4], [3, 5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "8dfdfc2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "eval_pipeline = AutomaticSpeechRecognitionPipeline(\n",
    "            model=model,\n",
    "            feature_extractor=feature_extractor,\n",
    "            tokenizer=tokenizer,\n",
    "            device=\"cuda:0\", # Use GPU 0, or -1 for CPU\n",
    ")\n",
    "#forced_decoder_ids = processor.get_decoder_prompt_ids(language=\"english\", task=\"transcribe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "02be0d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_audio_dir(s):\n",
    "    return os.path.join('/ceph/dpandya/notsofar/nsfd_adap_segments/eval/', s)\n",
    "\n",
    "df = pd.read_csv(\"/ceph/dpandya/notsofar/nsfd_adap_segments/eval_segments.csv\")\n",
    "df['segmented_audio_file'] = df['segmented_audio_file'].apply(add_audio_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "9f2aaf78",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You have explicitly specified `forced_decoder_ids`. Please remove the `forced_decoder_ids` argument in favour of `input_ids` or `decoder_input_ids` respectively.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[105], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43meval_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msegmented_audio_file\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/work/dpandya/miniconda3/envs/onlyWhisper/lib/python3.11/site-packages/transformers/pipelines/automatic_speech_recognition.py:283\u001b[0m, in \u001b[0;36mAutomaticSpeechRecognitionPipeline.__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    224\u001b[0m     inputs: Union[np\u001b[38;5;241m.\u001b[39mndarray, \u001b[38;5;28mbytes\u001b[39m, \u001b[38;5;28mstr\u001b[39m],\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    226\u001b[0m ):\n\u001b[1;32m    227\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;124;03m    Transcribe the audio sequence(s) given as inputs to text. See the [`AutomaticSpeechRecognitionPipeline`]\u001b[39;00m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;124;03m    documentation for more information.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;124;03m                `\"\".join(chunk[\"text\"] for chunk in output[\"chunks\"])`.\u001b[39;00m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 283\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/work/dpandya/miniconda3/envs/onlyWhisper/lib/python3.11/site-packages/transformers/pipelines/base.py:1360\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1356\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m can_use_iterator:\n\u001b[1;32m   1357\u001b[0m     final_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_iterator(\n\u001b[1;32m   1358\u001b[0m         inputs, num_workers, batch_size, preprocess_params, forward_params, postprocess_params\n\u001b[1;32m   1359\u001b[0m     )\n\u001b[0;32m-> 1360\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(final_iterator)\n\u001b[1;32m   1361\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n\u001b[1;32m   1362\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/work/dpandya/miniconda3/envs/onlyWhisper/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py:124\u001b[0m, in \u001b[0;36mPipelineIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader_batch_item()\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# We're out of items within a batch\u001b[39;00m\n\u001b[0;32m--> 124\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterator)\n\u001b[1;32m    125\u001b[0m processed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfer(item, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams)\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m# We now have a batch of \"inferred things\".\u001b[39;00m\n",
      "File \u001b[0;32m/work/dpandya/miniconda3/envs/onlyWhisper/lib/python3.11/site-packages/transformers/pipelines/pt_utils.py:269\u001b[0m, in \u001b[0;36mPipelinePackIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    266\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m accumulator\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_last:\n\u001b[0;32m--> 269\u001b[0m     processed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader_batch_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    271\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(processed, torch\u001b[38;5;241m.\u001b[39mTensor):\n",
      "File \u001b[0;32m/work/dpandya/miniconda3/envs/onlyWhisper/lib/python3.11/site-packages/transformers/pipelines/base.py:1286\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m   1284\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[1;32m   1285\u001b[0m         model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m-> 1286\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1287\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m   1288\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/work/dpandya/miniconda3/envs/onlyWhisper/lib/python3.11/site-packages/transformers/pipelines/automatic_speech_recognition.py:521\u001b[0m, in \u001b[0;36mAutomaticSpeechRecognitionPipeline._forward\u001b[0;34m(self, model_inputs, return_timestamps, **generate_kwargs)\u001b[0m\n\u001b[1;32m    518\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeneration_config\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m generate_kwargs:\n\u001b[1;32m    519\u001b[0m     generate_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeneration_config\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgeneration_config\n\u001b[0;32m--> 521\u001b[0m tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgenerate_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[38;5;66;03m# whisper longform generation stores timestamps in \"segments\"\u001b[39;00m\n\u001b[1;32m    527\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_timestamps \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mword\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseq2seq_whisper\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m/work/dpandya/miniconda3/envs/onlyWhisper/lib/python3.11/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/work/dpandya/miniconda3/envs/onlyWhisper/lib/python3.11/site-packages/transformers/generation/utils.py:2358\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, **kwargs)\u001b[0m\n\u001b[1;32m   2347\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   2348\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are calling .generate() with the `input_ids` being on a device type different\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2349\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m than your model\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms device. `input_ids` is on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_ids\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, whereas the model\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2354\u001b[0m         \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[1;32m   2355\u001b[0m     )\n\u001b[1;32m   2357\u001b[0m \u001b[38;5;66;03m# 9. prepare logits processors and stopping criteria\u001b[39;00m\n\u001b[0;32m-> 2358\u001b[0m prepared_logits_processor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_logits_processor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2359\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2360\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids_seq_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2361\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_input_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_tensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2362\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefix_allowed_tokens_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprefix_allowed_tokens_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2363\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2364\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_tensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2365\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2366\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnegative_prompt_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnegative_prompt_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2367\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnegative_prompt_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnegative_prompt_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2368\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2369\u001b[0m prepared_stopping_criteria \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_stopping_criteria(\n\u001b[1;32m   2370\u001b[0m     generation_config\u001b[38;5;241m=\u001b[39mgeneration_config, stopping_criteria\u001b[38;5;241m=\u001b[39mstopping_criteria, tokenizer\u001b[38;5;241m=\u001b[39mtokenizer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m   2371\u001b[0m )\n\u001b[1;32m   2373\u001b[0m \u001b[38;5;66;03m# Set model_kwargs `use_cache` so we can use it later in forward runs\u001b[39;00m\n",
      "File \u001b[0;32m/work/dpandya/miniconda3/envs/onlyWhisper/lib/python3.11/site-packages/transformers/generation/utils.py:1169\u001b[0m, in \u001b[0;36mGenerationMixin._get_logits_processor\u001b[0;34m(self, generation_config, input_ids_seq_length, encoder_input_ids, prefix_allowed_tokens_fn, logits_processor, device, model_kwargs, negative_prompt_ids, negative_prompt_attention_mask)\u001b[0m\n\u001b[1;32m   1160\u001b[0m     processors\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m   1161\u001b[0m         SuppressTokensAtBeginLogitsProcessor(\n\u001b[1;32m   1162\u001b[0m             generation_config\u001b[38;5;241m.\u001b[39mbegin_suppress_tokens,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1165\u001b[0m         )\n\u001b[1;32m   1166\u001b[0m     )\n\u001b[1;32m   1167\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m generation_config\u001b[38;5;241m.\u001b[39mforced_decoder_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1168\u001b[0m     \u001b[38;5;66;03m# TODO (sanchit): move this exception to GenerationConfig.validate() when TF & FLAX are aligned with PT\u001b[39;00m\n\u001b[0;32m-> 1169\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1170\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have explicitly specified `forced_decoder_ids`. Please remove the `forced_decoder_ids` argument \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1171\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124min favour of `input_ids` or `decoder_input_ids` respectively.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1172\u001b[0m     )\n\u001b[1;32m   1174\u001b[0m \u001b[38;5;66;03m# TODO (joao): find a strategy to specify the order of the processors\u001b[39;00m\n\u001b[1;32m   1175\u001b[0m processors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_criteria_processor_list(processors, logits_processor)\n",
      "\u001b[0;31mValueError\u001b[0m: You have explicitly specified `forced_decoder_ids`. Please remove the `forced_decoder_ids` argument in favour of `input_ids` or `decoder_input_ids` respectively."
     ]
    }
   ],
   "source": [
    "eval_pipeline(list(df['segmented_audio_file'])[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5686bda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/ceph/dpandya/notsofar/nsfd_adap_segments/eval_segments.csv\")\n",
    "df['duration'] = (df['stop'] - df['start'])/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "807f784b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.models.whisper.modeling_whisper.WhisperModel"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import WhisperForConditionalGeneration\n",
    "\n",
    "type(WhisperForConditionalGeneration.from_pretrained('openai/whisper-small').model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c208bce4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_audio_file</th>\n",
       "      <th>segmented_audio_file</th>\n",
       "      <th>segmented_text</th>\n",
       "      <th>start</th>\n",
       "      <th>stop</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>/ceph/dpandya/notsofar/eval_set/240825.1_eval_...</td>\n",
       "      <td>MTG_32049_ch0_segment_16.wav</td>\n",
       "      <td>And &lt;ST/&gt; And I'll check when that uh scientis...</td>\n",
       "      <td>356500.0</td>\n",
       "      <td>356890.0</td>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>/ceph/dpandya/notsofar/eval_set/240825.1_eval_...</td>\n",
       "      <td>MTG_32331_ch0_segment_10.wav</td>\n",
       "      <td>Uh, the trees &lt;ST/&gt; &lt;ST/&gt; still have some leav...</td>\n",
       "      <td>210130.0</td>\n",
       "      <td>232440.0</td>\n",
       "      <td>22.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1844</th>\n",
       "      <td>/ceph/dpandya/notsofar/eval_set/240825.1_eval_...</td>\n",
       "      <td>MTG_32180_ch0_segment_3.wav</td>\n",
       "      <td>I have an idea about something that might be v...</td>\n",
       "      <td>48610.0</td>\n",
       "      <td>68750.0</td>\n",
       "      <td>20.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1353</th>\n",
       "      <td>/ceph/dpandya/notsofar/eval_set/240825.1_eval_...</td>\n",
       "      <td>MTG_32087_ch0_segment_15.wav</td>\n",
       "      <td>&lt;ST/&gt; and uh &lt;FILL/&gt; just to get as many diffe...</td>\n",
       "      <td>351810.0</td>\n",
       "      <td>352950.0</td>\n",
       "      <td>1.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>/ceph/dpandya/notsofar/eval_set/240825.1_eval_...</td>\n",
       "      <td>MTG_32000_ch0_segment_13.wav</td>\n",
       "      <td>&lt;ST/&gt; this &lt;ST/&gt; &lt;UNKNOWN/&gt; &lt;ST/&gt; meeting? Wha...</td>\n",
       "      <td>283220.0</td>\n",
       "      <td>307100.0</td>\n",
       "      <td>23.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>/ceph/dpandya/notsofar/eval_set/240825.1_eval_...</td>\n",
       "      <td>MTG_32054_ch0_segment_12.wav</td>\n",
       "      <td>&lt;ST/&gt; and that, we rent one site per day or is...</td>\n",
       "      <td>256070.0</td>\n",
       "      <td>280160.0</td>\n",
       "      <td>24.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>/ceph/dpandya/notsofar/eval_set/240825.1_eval_...</td>\n",
       "      <td>MTG_32086_ch0_segment_1.wav</td>\n",
       "      <td>Hi &lt;PName&gt; Rachel &lt;/PName&gt; . Welcome. &lt;BA/&gt; Th...</td>\n",
       "      <td>6740.0</td>\n",
       "      <td>31450.0</td>\n",
       "      <td>24.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1422</th>\n",
       "      <td>/ceph/dpandya/notsofar/eval_set/240825.1_eval_...</td>\n",
       "      <td>MTG_32312_ch0_segment_7.wav</td>\n",
       "      <td>Refrigerator magnets. I think &lt;ST/&gt; &lt;ST/&gt; on t...</td>\n",
       "      <td>145830.0</td>\n",
       "      <td>168830.0</td>\n",
       "      <td>23.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1691</th>\n",
       "      <td>/ceph/dpandya/notsofar/eval_set/240825.1_eval_...</td>\n",
       "      <td>MTG_32322_ch0_segment_6.wav</td>\n",
       "      <td>Um. Yeah I would like to actually &lt;ST/&gt; &lt;ST/&gt; ...</td>\n",
       "      <td>113010.0</td>\n",
       "      <td>137610.0</td>\n",
       "      <td>24.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1404</th>\n",
       "      <td>/ceph/dpandya/notsofar/eval_set/240825.1_eval_...</td>\n",
       "      <td>MTG_32338_ch0_segment_5.wav</td>\n",
       "      <td>&lt;ST/&gt; is a big part of it is what I'm doing wi...</td>\n",
       "      <td>96240.0</td>\n",
       "      <td>120260.0</td>\n",
       "      <td>24.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>540 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    original_audio_file  \\\n",
       "881   /ceph/dpandya/notsofar/eval_set/240825.1_eval_...   \n",
       "453   /ceph/dpandya/notsofar/eval_set/240825.1_eval_...   \n",
       "1844  /ceph/dpandya/notsofar/eval_set/240825.1_eval_...   \n",
       "1353  /ceph/dpandya/notsofar/eval_set/240825.1_eval_...   \n",
       "281   /ceph/dpandya/notsofar/eval_set/240825.1_eval_...   \n",
       "...                                                 ...   \n",
       "244   /ceph/dpandya/notsofar/eval_set/240825.1_eval_...   \n",
       "997   /ceph/dpandya/notsofar/eval_set/240825.1_eval_...   \n",
       "1422  /ceph/dpandya/notsofar/eval_set/240825.1_eval_...   \n",
       "1691  /ceph/dpandya/notsofar/eval_set/240825.1_eval_...   \n",
       "1404  /ceph/dpandya/notsofar/eval_set/240825.1_eval_...   \n",
       "\n",
       "              segmented_audio_file  \\\n",
       "881   MTG_32049_ch0_segment_16.wav   \n",
       "453   MTG_32331_ch0_segment_10.wav   \n",
       "1844   MTG_32180_ch0_segment_3.wav   \n",
       "1353  MTG_32087_ch0_segment_15.wav   \n",
       "281   MTG_32000_ch0_segment_13.wav   \n",
       "...                            ...   \n",
       "244   MTG_32054_ch0_segment_12.wav   \n",
       "997    MTG_32086_ch0_segment_1.wav   \n",
       "1422   MTG_32312_ch0_segment_7.wav   \n",
       "1691   MTG_32322_ch0_segment_6.wav   \n",
       "1404   MTG_32338_ch0_segment_5.wav   \n",
       "\n",
       "                                         segmented_text     start      stop  \\\n",
       "881   And <ST/> And I'll check when that uh scientis...  356500.0  356890.0   \n",
       "453   Uh, the trees <ST/> <ST/> still have some leav...  210130.0  232440.0   \n",
       "1844  I have an idea about something that might be v...   48610.0   68750.0   \n",
       "1353  <ST/> and uh <FILL/> just to get as many diffe...  351810.0  352950.0   \n",
       "281   <ST/> this <ST/> <UNKNOWN/> <ST/> meeting? Wha...  283220.0  307100.0   \n",
       "...                                                 ...       ...       ...   \n",
       "244   <ST/> and that, we rent one site per day or is...  256070.0  280160.0   \n",
       "997   Hi <PName> Rachel </PName> . Welcome. <BA/> Th...    6740.0   31450.0   \n",
       "1422  Refrigerator magnets. I think <ST/> <ST/> on t...  145830.0  168830.0   \n",
       "1691  Um. Yeah I would like to actually <ST/> <ST/> ...  113010.0  137610.0   \n",
       "1404  <ST/> is a big part of it is what I'm doing wi...   96240.0  120260.0   \n",
       "\n",
       "      duration  \n",
       "881       0.39  \n",
       "453      22.31  \n",
       "1844     20.14  \n",
       "1353      1.14  \n",
       "281      23.88  \n",
       "...        ...  \n",
       "244      24.09  \n",
       "997      24.71  \n",
       "1422     23.00  \n",
       "1691     24.60  \n",
       "1404     24.02  \n",
       "\n",
       "[540 rows x 6 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "df.sample(540, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca4a6f15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-04 13:56:46.124199: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-11-04 13:56:46.124262: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-11-04 13:56:46.125895: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-11-04 13:56:46.135069: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-04 13:56:46.884748: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "model = adapters.WhisperAdapterModel.from_pretrained(\n",
    "    \"openai/whisper-medium\",\n",
    "    language=\"english\",\n",
    "    task=\"transcribe\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19cdee55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'seqBN_r16'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_adapter(\n",
    "    \"/ceph/dpandya/notsofar/nsfd_adap_segments/adapter_base/medium/seqBN_r16/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98f9a48a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seqBN_r8\n",
      "seqBN_r32\n",
      "seqBN_r16\n",
      "seqBN_r4\n"
     ]
    }
   ],
   "source": [
    "d_dir = \"/ceph/dpandya/notsofar/nsfd_adap_segments/adapter_base/medium/\"\n",
    "dd = os.listdir(d_dir)\n",
    "for d in dd:\n",
    "    if os.path.isdir(os.path.join(d_dir, d)):\n",
    "        print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c7441059",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_json('/ceph/dpandya/notsofar/nsfd_adap_segments/adapter_base/medium/experiment_results.json')\n",
    "rf4 = pd.DataFrame(results['seqBN_r32']['log_history'])[:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1bd2c7",
   "metadata": {},
   "source": [
    "- /ceph/dpandya/notsofar/nsfd_all.csv -- all the audio files\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5acc5576",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio_files</th>\n",
       "      <th>transcription_file</th>\n",
       "      <th>mic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>sc_rockfall_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>sc_plaza_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>sc_rockfall_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>sc_rockfall_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>sc_rockfall_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>sc_rockfall_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>sc_plaza_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>sc_meetup_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>sc_plaza_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>sc_rockfall_2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          audio_files  \\\n",
       "0   /ceph/dpandya/notsofar/train_set/240825.1_trai...   \n",
       "1   /ceph/dpandya/notsofar/train_set/240825.1_trai...   \n",
       "2   /ceph/dpandya/notsofar/train_set/240825.1_trai...   \n",
       "3   /ceph/dpandya/notsofar/train_set/240825.1_trai...   \n",
       "4   /ceph/dpandya/notsofar/train_set/240825.1_trai...   \n",
       "..                                                ...   \n",
       "67  /ceph/dpandya/notsofar/train_set/240825.1_trai...   \n",
       "68  /ceph/dpandya/notsofar/train_set/240825.1_trai...   \n",
       "69  /ceph/dpandya/notsofar/train_set/240825.1_trai...   \n",
       "70  /ceph/dpandya/notsofar/train_set/240825.1_trai...   \n",
       "71  /ceph/dpandya/notsofar/train_set/240825.1_trai...   \n",
       "\n",
       "                                   transcription_file            mic  \n",
       "0   /ceph/dpandya/notsofar/train_set/240825.1_trai...  sc_rockfall_1  \n",
       "1   /ceph/dpandya/notsofar/train_set/240825.1_trai...     sc_plaza_0  \n",
       "2   /ceph/dpandya/notsofar/train_set/240825.1_trai...  sc_rockfall_1  \n",
       "3   /ceph/dpandya/notsofar/train_set/240825.1_trai...  sc_rockfall_2  \n",
       "4   /ceph/dpandya/notsofar/train_set/240825.1_trai...  sc_rockfall_0  \n",
       "..                                                ...            ...  \n",
       "67  /ceph/dpandya/notsofar/train_set/240825.1_trai...  sc_rockfall_2  \n",
       "68  /ceph/dpandya/notsofar/train_set/240825.1_trai...     sc_plaza_0  \n",
       "69  /ceph/dpandya/notsofar/train_set/240825.1_trai...    sc_meetup_0  \n",
       "70  /ceph/dpandya/notsofar/train_set/240825.1_trai...     sc_plaza_0  \n",
       "71  /ceph/dpandya/notsofar/train_set/240825.1_trai...  sc_rockfall_2  \n",
       "\n",
       "[72 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pd.read_csv('/ceph/dpandya/notsofar/dev_set/240825.1_dev1/segmented_audios.csv')\n",
    "pd.read_csv('/ceph/dpandya/notsofar/newNotsofar/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3062fbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(s):\n",
    "    # Convert to string to handle potential non-string inputs gracefully\n",
    "    s = str(s)\n",
    "    \n",
    "    # 1. Remove text enclosed in angle brackets (e.g., <ST>, <UNKNOWN>)\n",
    "    s = re.sub(r'<[^>]+>', '', s)\n",
    "    \n",
    "    # 2. Remove punctuation\n",
    "    # This regex matches any character that is NOT a word character (alphanumeric + underscore) or whitespace\n",
    "    s = re.sub(r'[^\\w\\s]', '', s)\n",
    "    \n",
    "    # 3. Remove extra spaces (replace multiple spaces with a single space)\n",
    "    s = re.sub(r'\\s+', ' ', s)\n",
    "    \n",
    "    # 4. Remove leading and trailing spaces\n",
    "    s = s.strip()\n",
    "    \n",
    "    # 5. Convert to lowercase for case-insensitive comparison\n",
    "    return s.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5987c1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('<ST/> we got a <ST/> we got a big budget in the office uh regarding snacks uh yeah <ST/>',\n",
       " 'we got a we got a big budget in the office uh regarding snacks uh yeah')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samp = '/ceph/dpandya/notsofar/eval_set/240825.1_eval_full_with_GT/MTG/'\n",
    "df = pd.read_csv(os.path.join(samp, 'eval.csv'))\n",
    "trSample = pd.read_json(df['gt_transcription_files'].iloc[0])\n",
    "trSample['text'].iloc[1], clean_text(trSample['text'].iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "088c9ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dataset_info.json', 'data-00000-of-00001.arrow', 'cache-941e4f085085b177.arrow', 'state.json']\n"
     ]
    }
   ],
   "source": [
    "#d = pd.read_csv('/ceph/dpandya/notsofar/train_set/240825.1_train/segmented_audios.csv')\n",
    "#pd.read_csv('/ceph/dpandya/notsofar/train_set/240825.1_train')\n",
    "#pd.read_csv('/ceph/dpandya/notsofar/nsfd_all.csv')\n",
    "print(os.listdir('/ceph/dpandya/notsofar/train_set/small_train_features/medium/'))\n",
    "#pd.read_csv('/ceph/dpandya/notsofar/train_set/240825.1_train/segmented_audios.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ba27210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>org_audio_file</th>\n",
       "      <th>segmented_audio_file</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>alright everyone let us continue on with our ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>have any of you guys used it yet? um not not y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>i would i would love to try it to see. but is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>so you don't have to have someone monitoring y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>oh i see, oh i see, ok. and you could just to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6776</th>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>i think both is is a good option. you think bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6777</th>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>there could be um like toys and things for kid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6778</th>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>what i feel wasn't set up an ice cream cone li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6779</th>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>maybe like each level like the first level is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6780</th>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>ice cream. most personalized ice cream. journe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6781 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         org_audio_file  \\\n",
       "0     /ceph/dpandya/notsofar/train_set/240825.1_trai...   \n",
       "1     /ceph/dpandya/notsofar/train_set/240825.1_trai...   \n",
       "2     /ceph/dpandya/notsofar/train_set/240825.1_trai...   \n",
       "3     /ceph/dpandya/notsofar/train_set/240825.1_trai...   \n",
       "4     /ceph/dpandya/notsofar/train_set/240825.1_trai...   \n",
       "...                                                 ...   \n",
       "6776  /ceph/dpandya/notsofar/train_set/240825.1_trai...   \n",
       "6777  /ceph/dpandya/notsofar/train_set/240825.1_trai...   \n",
       "6778  /ceph/dpandya/notsofar/train_set/240825.1_trai...   \n",
       "6779  /ceph/dpandya/notsofar/train_set/240825.1_trai...   \n",
       "6780  /ceph/dpandya/notsofar/train_set/240825.1_trai...   \n",
       "\n",
       "                                   segmented_audio_file  \\\n",
       "0     /ceph/dpandya/notsofar/train_set/240825.1_trai...   \n",
       "1     /ceph/dpandya/notsofar/train_set/240825.1_trai...   \n",
       "2     /ceph/dpandya/notsofar/train_set/240825.1_trai...   \n",
       "3     /ceph/dpandya/notsofar/train_set/240825.1_trai...   \n",
       "4     /ceph/dpandya/notsofar/train_set/240825.1_trai...   \n",
       "...                                                 ...   \n",
       "6776  /ceph/dpandya/notsofar/train_set/240825.1_trai...   \n",
       "6777  /ceph/dpandya/notsofar/train_set/240825.1_trai...   \n",
       "6778  /ceph/dpandya/notsofar/train_set/240825.1_trai...   \n",
       "6779  /ceph/dpandya/notsofar/train_set/240825.1_trai...   \n",
       "6780  /ceph/dpandya/notsofar/train_set/240825.1_trai...   \n",
       "\n",
       "                                                   text  \n",
       "0      alright everyone let us continue on with our ...  \n",
       "1     have any of you guys used it yet? um not not y...  \n",
       "2     i would i would love to try it to see. but is ...  \n",
       "3     so you don't have to have someone monitoring y...  \n",
       "4     oh i see, oh i see, ok. and you could just to ...  \n",
       "...                                                 ...  \n",
       "6776  i think both is is a good option. you think bo...  \n",
       "6777  there could be um like toys and things for kid...  \n",
       "6778  what i feel wasn't set up an ice cream cone li...  \n",
       "6779  maybe like each level like the first level is ...  \n",
       "6780  ice cream. most personalized ice cream. journe...  \n",
       "\n",
       "[6781 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd = pd.read_csv('/ceph/dpandya/notsofar/train_set/240825.1_train/new_segmented_audios/new_segmented_audios.csv')\n",
    "dd.dropna(subset=['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b142f81d",
   "metadata": {},
   "source": [
    "- randomly select a single-channel audio stream from the meetings\n",
    "- compile a list of these meetings\n",
    "- create a df with their transcription files\n",
    "- Divide them into train and eval sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31661da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir =  '/ceph/dpandya/notsofar/train_set/240825.1_train/MTG/'\n",
    "eval_dir = '/ceph/dpandya/notsofar/eval_set/240825.1_eval_full_with_GT/MTG/'\n",
    "train_meetings = os.listdir('/ceph/dpandya/notsofar/train_set/240825.1_train/MTG/')\n",
    "eval_meetings = os.listdir('/ceph/dpandya/notsofar/eval_set/240825.1_eval_full_with_GT/MTG/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3f65841d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = []\n",
    "transcription_files = []\n",
    "mic = []\n",
    "# Iterate through all the train meeting dir and choosing a random single channel audio stream\n",
    "for meet in train_meetings:\n",
    "    stream_list = []\n",
    "    # Collecting all the streams for a meeting\n",
    "    for stream in os.listdir(os.path.join(train_dir, meet)):\n",
    "        if os.path.isdir(os.path.join(train_dir, meet, stream)):\n",
    "            if stream.split('_')[0] == 'sc':\n",
    "                stream_list.append(os.path.join(train_dir, meet, stream, 'ch0.wav'))\n",
    "    random_ = random.choice(stream_list)\n",
    "    \n",
    "    mic.append(random_.split('/')[-2])\n",
    "    train_files.append(random_)\n",
    "    transcription_files.append(os.path.join(train_dir, meet, 'gt_transcription.json'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2ede91d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the same process for the eval files, choosing a random single channel audio stream\n",
    "eval_files = []\n",
    "eval_trans = []\n",
    "eval_mic = []\n",
    "# Iterate through all the eval meeting dir and choosing a random single channel audio stream\n",
    "for meet in eval_meetings:\n",
    "    stream_list = []\n",
    "    # Collecting all the streams for a meeting\n",
    "    if os.path.isdir(os.path.join(eval_dir, meet)):\n",
    "        for stream in os.listdir(os.path.join(eval_dir, meet)):\n",
    "            if os.path.isdir(os.path.join(eval_dir, meet, stream)):\n",
    "                if stream.split('_')[0] == 'sc':\n",
    "                    stream_list.append(os.path.join(eval_dir, meet, stream, 'ch0.wav'))\n",
    "        random_ = random.choice(stream_list)\n",
    "    \n",
    "        eval_mic.append(random_.split('/')[-2])\n",
    "        eval_files.append(random_)\n",
    "        eval_trans.append(os.path.join(eval_dir, meet, 'gt_transcription.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "69b3a0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame()\n",
    "train_df['audio_files'] = train_files\n",
    "train_df['transcription_file'] = transcription_files\n",
    "train_df['mic'] = mic\n",
    "\n",
    "test_df = pd.DataFrame()\n",
    "test_df['audio_files'] = eval_files\n",
    "test_df['transcription_files'] = eval_trans\n",
    "test_df['mic'] = eval_mic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c7559661",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('/ceph/dpandya/notsofar/newNotsofar/train.csv', index=False)\n",
    "test_df.to_csv('/ceph/dpandya/notsofar/newNotsofar/test.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "onlyWhisper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

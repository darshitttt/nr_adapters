{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "231b7727",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/dpandya/miniconda3/envs/onlyWhisper/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from IPython.display import display, Audio\n",
    "import librosa\n",
    "import random\n",
    "import whisper\n",
    "import adapters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0f414a9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['original_audio_file', 'segmented_audio_file', 'segmented_text',\n",
       "       'start', 'stop', 'preds_large', 'WER', 'preds_medium'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ee = pd.read_csv('/ceph/dpandya/notsofar/nsfd_adap_segments/baseline_large.csv')\n",
    "ee.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fb02e95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import eval_utils as eu\n",
    "\n",
    "ee['medium_wer'] = ee.apply(lambda x: eu.compute_wer(x['preds_medium'], x['segmented_text']), axis=1)\n",
    "ee['large_wer'] = ee.apply(lambda x: eu.compute_wer(x['preds_large'], x['segmented_text']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d3ee0ce7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4117449623708684, 0.37912193045450343)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ee['medium_wer'].mean(), ee['large_wer'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30e64504",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"adapter_name = model.load_adapter(\\n    '/ceph/dpandya/notsofar/nsfd_adap_segments/adapter_base/medium/seqBN_r16/',\\n    set_active=True\\n)\\n#model.config.max_length=512\\nmodel.set_active_adapters(adapter_name)\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutomaticSpeechRecognitionPipeline\n",
    "from transformers import WhisperFeatureExtractor, WhisperTokenizer, pipeline, WhisperProcessor\n",
    "from transformers import WhisperForConditionalGeneration\n",
    "import torch\n",
    "\n",
    "model_name = 'openai/whisper-medium'\n",
    "\n",
    "feature_extractor = WhisperFeatureExtractor.from_pretrained(model_name, language=\"english\", task=\"transcribe\", chunk_length=30)\n",
    "tokenizer = WhisperTokenizer.from_pretrained(model_name, language=\"english\", task=\"transcribe\")\n",
    "processor = WhisperProcessor.from_pretrained(model_name, language=\"english\", task=\"transcribe\", truncation=True)\n",
    "\n",
    "#model = adapters.WhisperAdapterModel.from_pretrained(model_name, language=\"english\", task=\"transcribe\")\n",
    "model = adapters.WhisperAdapterModel.from_pretrained(model_name)\n",
    "model2 = WhisperForConditionalGeneration.from_pretrained(model_name)\n",
    "adapter_dir = '/ceph/dpandya/notsofar/nsfd_adap_segments/adapter_base/medium/seqBN_r16/'\n",
    "#model.config.max_length = 512\n",
    "#model.config.use_cache = False\n",
    "'''adapter_name = model.load_adapter(\n",
    "    '/ceph/dpandya/notsofar/nsfd_adap_segments/adapter_base/medium/seqBN_r16/',\n",
    "    set_active=True\n",
    ")\n",
    "#model.config.max_length=512\n",
    "model.set_active_adapters(adapter_name)'''\n",
    "#ddf = pd.read_csv('/ceph/dpandya/notsofar/nsfd_adap_segments/adapter_base/medium/eval_seqBN_r8.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac64730a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There are adapters available but none are activated for the forward pass.\n"
     ]
    }
   ],
   "source": [
    "adapters.init(model2)\n",
    "adap_name = model2.load_adapter('/ceph/dpandya/notsofar/nsfd_adap_segments/adapter_base/medium/seqBN_r16/')\n",
    "model2.set_active_adapters(adap_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e2b66687",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.generation_config._from_model_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1116d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''model.config.forced_decoder_ids = None\n",
    "model.config.suppress_tokens = []\n",
    "model.generation_config.forced_decoder_ids = None\n",
    "model.generation_config._from_model_config = True'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0294b540",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.generation_config.input_ids = model.generation_config.forced_decoder_ids\n",
    "model.generation_config.forced_decoder_ids = None\n",
    "model.generation_config.alignment_heads = [[2, 2], [3, 0], [3, 2], [3, 3], [3, 4], [3, 5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8dfdfc2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "eval_pipeline = AutomaticSpeechRecognitionPipeline(\n",
    "            model=model2,\n",
    "            feature_extractor=processor.feature_extractor,\n",
    "            tokenizer=processor.tokenizer,\n",
    "            device=\"cuda:0\", # Use GPU 0, or -1 for CPU\n",
    "            chunk_length_s=30\n",
    ")\n",
    "forced_decoder_ids = processor.get_decoder_prompt_ids(language=\"english\", task=\"transcribe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02be0d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "\n",
    "def add_audio_dir(s):\n",
    "    return os.path.join('/ceph/dpandya/notsofar/nsfd_adap_segments/eval/', s)\n",
    "\n",
    "df = pd.read_csv(\"/ceph/dpandya/notsofar/nsfd_adap_segments/eval_segments.csv\")[0:5]\n",
    "df['segmented_audio_file'] = df['segmented_audio_file'].apply(add_audio_dir)\n",
    "\n",
    "eval_files = {'audio':list(df['segmented_audio_file'])}\n",
    "eval_ds = datasets.Dataset.from_dict(eval_files).cast_column('audio', datasets.Audio(sampling_rate=16000))\n",
    "eval_ds = eval_ds.add_column(\"text\", list(df['segmented_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f2aaf78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating ...:   0%|          | 0/5 [00:00<?, ?it/s]/work/dpandya/miniconda3/envs/onlyWhisper/lib/python3.11/site-packages/transformers/models/whisper/generation_whisper.py:573: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "Evaluating ...: 100%|██████████| 5/5 [00:19<00:00,  3.81s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from transformers.pipelines.pt_utils import KeyDataset\n",
    "\n",
    "predictions = []\n",
    "\n",
    "for prediction in tqdm(\n",
    "    eval_pipeline(\n",
    "        #list(eval_df['audio_file']),\n",
    "        KeyDataset(eval_ds,'audio'),\n",
    "        batch_size=1,\n",
    "        generate_kwargs={\"forced_decoder_ids\": forced_decoder_ids},\n",
    "        #max_new_tokens=256\n",
    "    ), total=len(eval_ds), desc='Evaluating ...'\n",
    "):\n",
    "    predictions.append(prediction['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da5a27f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"OK, so... Will we be here? ...we got a very good budget in the office uh regarding snacks um yeah. Mm-hmm. Yeah. Mm-hmm. Oh great. Yeah, regarding snacks or like lunch on snacks? Sure. Yes. No, regarding snacks OK um and I know all of us and other people in the office, I just called you guys, so there's also other people in office that have different preferences uh for foods that have food restrictions.\",\n",
       " \"Um so even though we have a big budget, we wanna make the most out of it, so is there something that you guys would prefer to have or not to have in the office? Mm-hmm. A big budget means um on the quantity we can buy or the quality on the quality? The quality. The quality. Quality. Yeah. I'd go for quality, yeah. Mm-hmm. Yeah. Well I'm nuts about nuts. So if we're talking about quality... And I'm not just saying that. ...pastachios, pecans, and cashews. Mm-hmm. I'm not nuts about nuts.\",\n",
       " \"Isn't that kind of a waste of money? Like who eats that? Who eats that? Waste of money, we have budget though. That's for real. But still, it's still good. Yeah, but who eats it? Who can uh do it? Well, I do. Healthy people. Mm-hmm. That's right. They're the best snacks. They need healthy. Look, we want healthy boys and girls. Healthy girls can't eat that. I don't wanna eat it. I don't wanna be eating healthy, like I don't care for healthy snacks. I don't care for that. Um. You don't care for that? No, like I-I think it's kind of a waste of money. Alright, so what are you looking for? Yeah. Waste snack. I think we should have like ice cream or food. Ice cream is not a snack. It's just...\",\n",
       " \"I think it's a snack. I may know, may know. Chocolate bars. Uh, OK then at least if we have a soft serve machine, we can have like uh goat's milk. Uh, OK. For life's sake. Mmm. How about popcorn? Goa'en, goat's milk. How about milk ice cream? How about popcorn? Ice cream. How about popcorn? Mm-hmm. Popcorn is nice. Yeah, popcorn stinks out the office. Yeah. Popcorn stings out the office, one can't believe. But what aunt believes? It's right, think of like a great idea. Stinks out the office. Yeah, it does but uh let's have that in mind. Yeah.\",\n",
       " \"It smells so good. Would you want that to have a smell like popcorn? It's smelly. Popcorn is a very pleasant smell. It makes you feel good. OK, so no popcorn, no unhealthy snacks. We're not supposed to eat. No, no, no. No natural popcorn without the butter. OK. Popcorn is a very pleasant smell. This smell is not bad. No, and you need the unheadful, you need the unheavymissue about it. OK. Popcorn without butter. So you're talking about candy and things like that? Candy, sour patch, um twizzlers. Does that mean that it have a way too much flavor? Uh-huh. But then there is just like a little thing you know.\"]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5686bda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/ceph/dpandya/notsofar/nsfd_adap_segments/eval_segments.csv\")\n",
    "df['duration'] = (df['stop'] - df['start'])/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "807f784b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.models.whisper.modeling_whisper.WhisperModel"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import WhisperForConditionalGeneration\n",
    "\n",
    "type(WhisperForConditionalGeneration.from_pretrained('openai/whisper-small').model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c208bce4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_audio_file</th>\n",
       "      <th>segmented_audio_file</th>\n",
       "      <th>segmented_text</th>\n",
       "      <th>start</th>\n",
       "      <th>stop</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>/ceph/dpandya/notsofar/eval_set/240825.1_eval_...</td>\n",
       "      <td>MTG_32049_ch0_segment_16.wav</td>\n",
       "      <td>And &lt;ST/&gt; And I'll check when that uh scientis...</td>\n",
       "      <td>356500.0</td>\n",
       "      <td>356890.0</td>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>/ceph/dpandya/notsofar/eval_set/240825.1_eval_...</td>\n",
       "      <td>MTG_32331_ch0_segment_10.wav</td>\n",
       "      <td>Uh, the trees &lt;ST/&gt; &lt;ST/&gt; still have some leav...</td>\n",
       "      <td>210130.0</td>\n",
       "      <td>232440.0</td>\n",
       "      <td>22.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1844</th>\n",
       "      <td>/ceph/dpandya/notsofar/eval_set/240825.1_eval_...</td>\n",
       "      <td>MTG_32180_ch0_segment_3.wav</td>\n",
       "      <td>I have an idea about something that might be v...</td>\n",
       "      <td>48610.0</td>\n",
       "      <td>68750.0</td>\n",
       "      <td>20.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1353</th>\n",
       "      <td>/ceph/dpandya/notsofar/eval_set/240825.1_eval_...</td>\n",
       "      <td>MTG_32087_ch0_segment_15.wav</td>\n",
       "      <td>&lt;ST/&gt; and uh &lt;FILL/&gt; just to get as many diffe...</td>\n",
       "      <td>351810.0</td>\n",
       "      <td>352950.0</td>\n",
       "      <td>1.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>/ceph/dpandya/notsofar/eval_set/240825.1_eval_...</td>\n",
       "      <td>MTG_32000_ch0_segment_13.wav</td>\n",
       "      <td>&lt;ST/&gt; this &lt;ST/&gt; &lt;UNKNOWN/&gt; &lt;ST/&gt; meeting? Wha...</td>\n",
       "      <td>283220.0</td>\n",
       "      <td>307100.0</td>\n",
       "      <td>23.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>/ceph/dpandya/notsofar/eval_set/240825.1_eval_...</td>\n",
       "      <td>MTG_32054_ch0_segment_12.wav</td>\n",
       "      <td>&lt;ST/&gt; and that, we rent one site per day or is...</td>\n",
       "      <td>256070.0</td>\n",
       "      <td>280160.0</td>\n",
       "      <td>24.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>/ceph/dpandya/notsofar/eval_set/240825.1_eval_...</td>\n",
       "      <td>MTG_32086_ch0_segment_1.wav</td>\n",
       "      <td>Hi &lt;PName&gt; Rachel &lt;/PName&gt; . Welcome. &lt;BA/&gt; Th...</td>\n",
       "      <td>6740.0</td>\n",
       "      <td>31450.0</td>\n",
       "      <td>24.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1422</th>\n",
       "      <td>/ceph/dpandya/notsofar/eval_set/240825.1_eval_...</td>\n",
       "      <td>MTG_32312_ch0_segment_7.wav</td>\n",
       "      <td>Refrigerator magnets. I think &lt;ST/&gt; &lt;ST/&gt; on t...</td>\n",
       "      <td>145830.0</td>\n",
       "      <td>168830.0</td>\n",
       "      <td>23.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1691</th>\n",
       "      <td>/ceph/dpandya/notsofar/eval_set/240825.1_eval_...</td>\n",
       "      <td>MTG_32322_ch0_segment_6.wav</td>\n",
       "      <td>Um. Yeah I would like to actually &lt;ST/&gt; &lt;ST/&gt; ...</td>\n",
       "      <td>113010.0</td>\n",
       "      <td>137610.0</td>\n",
       "      <td>24.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1404</th>\n",
       "      <td>/ceph/dpandya/notsofar/eval_set/240825.1_eval_...</td>\n",
       "      <td>MTG_32338_ch0_segment_5.wav</td>\n",
       "      <td>&lt;ST/&gt; is a big part of it is what I'm doing wi...</td>\n",
       "      <td>96240.0</td>\n",
       "      <td>120260.0</td>\n",
       "      <td>24.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>540 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    original_audio_file  \\\n",
       "881   /ceph/dpandya/notsofar/eval_set/240825.1_eval_...   \n",
       "453   /ceph/dpandya/notsofar/eval_set/240825.1_eval_...   \n",
       "1844  /ceph/dpandya/notsofar/eval_set/240825.1_eval_...   \n",
       "1353  /ceph/dpandya/notsofar/eval_set/240825.1_eval_...   \n",
       "281   /ceph/dpandya/notsofar/eval_set/240825.1_eval_...   \n",
       "...                                                 ...   \n",
       "244   /ceph/dpandya/notsofar/eval_set/240825.1_eval_...   \n",
       "997   /ceph/dpandya/notsofar/eval_set/240825.1_eval_...   \n",
       "1422  /ceph/dpandya/notsofar/eval_set/240825.1_eval_...   \n",
       "1691  /ceph/dpandya/notsofar/eval_set/240825.1_eval_...   \n",
       "1404  /ceph/dpandya/notsofar/eval_set/240825.1_eval_...   \n",
       "\n",
       "              segmented_audio_file  \\\n",
       "881   MTG_32049_ch0_segment_16.wav   \n",
       "453   MTG_32331_ch0_segment_10.wav   \n",
       "1844   MTG_32180_ch0_segment_3.wav   \n",
       "1353  MTG_32087_ch0_segment_15.wav   \n",
       "281   MTG_32000_ch0_segment_13.wav   \n",
       "...                            ...   \n",
       "244   MTG_32054_ch0_segment_12.wav   \n",
       "997    MTG_32086_ch0_segment_1.wav   \n",
       "1422   MTG_32312_ch0_segment_7.wav   \n",
       "1691   MTG_32322_ch0_segment_6.wav   \n",
       "1404   MTG_32338_ch0_segment_5.wav   \n",
       "\n",
       "                                         segmented_text     start      stop  \\\n",
       "881   And <ST/> And I'll check when that uh scientis...  356500.0  356890.0   \n",
       "453   Uh, the trees <ST/> <ST/> still have some leav...  210130.0  232440.0   \n",
       "1844  I have an idea about something that might be v...   48610.0   68750.0   \n",
       "1353  <ST/> and uh <FILL/> just to get as many diffe...  351810.0  352950.0   \n",
       "281   <ST/> this <ST/> <UNKNOWN/> <ST/> meeting? Wha...  283220.0  307100.0   \n",
       "...                                                 ...       ...       ...   \n",
       "244   <ST/> and that, we rent one site per day or is...  256070.0  280160.0   \n",
       "997   Hi <PName> Rachel </PName> . Welcome. <BA/> Th...    6740.0   31450.0   \n",
       "1422  Refrigerator magnets. I think <ST/> <ST/> on t...  145830.0  168830.0   \n",
       "1691  Um. Yeah I would like to actually <ST/> <ST/> ...  113010.0  137610.0   \n",
       "1404  <ST/> is a big part of it is what I'm doing wi...   96240.0  120260.0   \n",
       "\n",
       "      duration  \n",
       "881       0.39  \n",
       "453      22.31  \n",
       "1844     20.14  \n",
       "1353      1.14  \n",
       "281      23.88  \n",
       "...        ...  \n",
       "244      24.09  \n",
       "997      24.71  \n",
       "1422     23.00  \n",
       "1691     24.60  \n",
       "1404     24.02  \n",
       "\n",
       "[540 rows x 6 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "df.sample(540, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca4a6f15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-04 13:56:46.124199: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-11-04 13:56:46.124262: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-11-04 13:56:46.125895: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-11-04 13:56:46.135069: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-04 13:56:46.884748: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "model = adapters.WhisperAdapterModel.from_pretrained(\n",
    "    \"openai/whisper-medium\",\n",
    "    language=\"english\",\n",
    "    task=\"transcribe\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19cdee55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'seqBN_r16'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_adapter(\n",
    "    \"/ceph/dpandya/notsofar/nsfd_adap_segments/adapter_base/medium/seqBN_r16/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98f9a48a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seqBN_r8\n",
      "seqBN_r32\n",
      "seqBN_r16\n",
      "seqBN_r4\n"
     ]
    }
   ],
   "source": [
    "d_dir = \"/ceph/dpandya/notsofar/nsfd_adap_segments/adapter_base/medium/\"\n",
    "dd = os.listdir(d_dir)\n",
    "for d in dd:\n",
    "    if os.path.isdir(os.path.join(d_dir, d)):\n",
    "        print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c7441059",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_json('/ceph/dpandya/notsofar/nsfd_adap_segments/adapter_base/medium/experiment_results.json')\n",
    "rf4 = pd.DataFrame(results['seqBN_r32']['log_history'])[:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1bd2c7",
   "metadata": {},
   "source": [
    "- /ceph/dpandya/notsofar/nsfd_all.csv -- all the audio files\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5acc5576",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio_files</th>\n",
       "      <th>transcription_file</th>\n",
       "      <th>mic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>sc_rockfall_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>sc_plaza_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>sc_rockfall_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>sc_rockfall_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>sc_rockfall_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>sc_rockfall_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>sc_plaza_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>sc_meetup_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>sc_plaza_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>sc_rockfall_2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          audio_files  \\\n",
       "0   /ceph/dpandya/notsofar/train_set/240825.1_trai...   \n",
       "1   /ceph/dpandya/notsofar/train_set/240825.1_trai...   \n",
       "2   /ceph/dpandya/notsofar/train_set/240825.1_trai...   \n",
       "3   /ceph/dpandya/notsofar/train_set/240825.1_trai...   \n",
       "4   /ceph/dpandya/notsofar/train_set/240825.1_trai...   \n",
       "..                                                ...   \n",
       "67  /ceph/dpandya/notsofar/train_set/240825.1_trai...   \n",
       "68  /ceph/dpandya/notsofar/train_set/240825.1_trai...   \n",
       "69  /ceph/dpandya/notsofar/train_set/240825.1_trai...   \n",
       "70  /ceph/dpandya/notsofar/train_set/240825.1_trai...   \n",
       "71  /ceph/dpandya/notsofar/train_set/240825.1_trai...   \n",
       "\n",
       "                                   transcription_file            mic  \n",
       "0   /ceph/dpandya/notsofar/train_set/240825.1_trai...  sc_rockfall_1  \n",
       "1   /ceph/dpandya/notsofar/train_set/240825.1_trai...     sc_plaza_0  \n",
       "2   /ceph/dpandya/notsofar/train_set/240825.1_trai...  sc_rockfall_1  \n",
       "3   /ceph/dpandya/notsofar/train_set/240825.1_trai...  sc_rockfall_2  \n",
       "4   /ceph/dpandya/notsofar/train_set/240825.1_trai...  sc_rockfall_0  \n",
       "..                                                ...            ...  \n",
       "67  /ceph/dpandya/notsofar/train_set/240825.1_trai...  sc_rockfall_2  \n",
       "68  /ceph/dpandya/notsofar/train_set/240825.1_trai...     sc_plaza_0  \n",
       "69  /ceph/dpandya/notsofar/train_set/240825.1_trai...    sc_meetup_0  \n",
       "70  /ceph/dpandya/notsofar/train_set/240825.1_trai...     sc_plaza_0  \n",
       "71  /ceph/dpandya/notsofar/train_set/240825.1_trai...  sc_rockfall_2  \n",
       "\n",
       "[72 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pd.read_csv('/ceph/dpandya/notsofar/dev_set/240825.1_dev1/segmented_audios.csv')\n",
    "pd.read_csv('/ceph/dpandya/notsofar/newNotsofar/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3062fbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(s):\n",
    "    # Convert to string to handle potential non-string inputs gracefully\n",
    "    s = str(s)\n",
    "    \n",
    "    # 1. Remove text enclosed in angle brackets (e.g., <ST>, <UNKNOWN>)\n",
    "    s = re.sub(r'<[^>]+>', '', s)\n",
    "    \n",
    "    # 2. Remove punctuation\n",
    "    # This regex matches any character that is NOT a word character (alphanumeric + underscore) or whitespace\n",
    "    s = re.sub(r'[^\\w\\s]', '', s)\n",
    "    \n",
    "    # 3. Remove extra spaces (replace multiple spaces with a single space)\n",
    "    s = re.sub(r'\\s+', ' ', s)\n",
    "    \n",
    "    # 4. Remove leading and trailing spaces\n",
    "    s = s.strip()\n",
    "    \n",
    "    # 5. Convert to lowercase for case-insensitive comparison\n",
    "    return s.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5987c1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('<ST/> we got a <ST/> we got a big budget in the office uh regarding snacks uh yeah <ST/>',\n",
       " 'we got a we got a big budget in the office uh regarding snacks uh yeah')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samp = '/ceph/dpandya/notsofar/eval_set/240825.1_eval_full_with_GT/MTG/'\n",
    "df = pd.read_csv(os.path.join(samp, 'eval.csv'))\n",
    "trSample = pd.read_json(df['gt_transcription_files'].iloc[0])\n",
    "trSample['text'].iloc[1], clean_text(trSample['text'].iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "088c9ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dataset_info.json', 'data-00000-of-00001.arrow', 'cache-941e4f085085b177.arrow', 'state.json']\n"
     ]
    }
   ],
   "source": [
    "#d = pd.read_csv('/ceph/dpandya/notsofar/train_set/240825.1_train/segmented_audios.csv')\n",
    "#pd.read_csv('/ceph/dpandya/notsofar/train_set/240825.1_train')\n",
    "#pd.read_csv('/ceph/dpandya/notsofar/nsfd_all.csv')\n",
    "print(os.listdir('/ceph/dpandya/notsofar/train_set/small_train_features/medium/'))\n",
    "#pd.read_csv('/ceph/dpandya/notsofar/train_set/240825.1_train/segmented_audios.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ba27210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>org_audio_file</th>\n",
       "      <th>segmented_audio_file</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>alright everyone let us continue on with our ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>have any of you guys used it yet? um not not y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>i would i would love to try it to see. but is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>so you don't have to have someone monitoring y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>oh i see, oh i see, ok. and you could just to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6776</th>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>i think both is is a good option. you think bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6777</th>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>there could be um like toys and things for kid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6778</th>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>what i feel wasn't set up an ice cream cone li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6779</th>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>maybe like each level like the first level is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6780</th>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>ice cream. most personalized ice cream. journe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6781 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         org_audio_file  \\\n",
       "0     /ceph/dpandya/notsofar/train_set/240825.1_trai...   \n",
       "1     /ceph/dpandya/notsofar/train_set/240825.1_trai...   \n",
       "2     /ceph/dpandya/notsofar/train_set/240825.1_trai...   \n",
       "3     /ceph/dpandya/notsofar/train_set/240825.1_trai...   \n",
       "4     /ceph/dpandya/notsofar/train_set/240825.1_trai...   \n",
       "...                                                 ...   \n",
       "6776  /ceph/dpandya/notsofar/train_set/240825.1_trai...   \n",
       "6777  /ceph/dpandya/notsofar/train_set/240825.1_trai...   \n",
       "6778  /ceph/dpandya/notsofar/train_set/240825.1_trai...   \n",
       "6779  /ceph/dpandya/notsofar/train_set/240825.1_trai...   \n",
       "6780  /ceph/dpandya/notsofar/train_set/240825.1_trai...   \n",
       "\n",
       "                                   segmented_audio_file  \\\n",
       "0     /ceph/dpandya/notsofar/train_set/240825.1_trai...   \n",
       "1     /ceph/dpandya/notsofar/train_set/240825.1_trai...   \n",
       "2     /ceph/dpandya/notsofar/train_set/240825.1_trai...   \n",
       "3     /ceph/dpandya/notsofar/train_set/240825.1_trai...   \n",
       "4     /ceph/dpandya/notsofar/train_set/240825.1_trai...   \n",
       "...                                                 ...   \n",
       "6776  /ceph/dpandya/notsofar/train_set/240825.1_trai...   \n",
       "6777  /ceph/dpandya/notsofar/train_set/240825.1_trai...   \n",
       "6778  /ceph/dpandya/notsofar/train_set/240825.1_trai...   \n",
       "6779  /ceph/dpandya/notsofar/train_set/240825.1_trai...   \n",
       "6780  /ceph/dpandya/notsofar/train_set/240825.1_trai...   \n",
       "\n",
       "                                                   text  \n",
       "0      alright everyone let us continue on with our ...  \n",
       "1     have any of you guys used it yet? um not not y...  \n",
       "2     i would i would love to try it to see. but is ...  \n",
       "3     so you don't have to have someone monitoring y...  \n",
       "4     oh i see, oh i see, ok. and you could just to ...  \n",
       "...                                                 ...  \n",
       "6776  i think both is is a good option. you think bo...  \n",
       "6777  there could be um like toys and things for kid...  \n",
       "6778  what i feel wasn't set up an ice cream cone li...  \n",
       "6779  maybe like each level like the first level is ...  \n",
       "6780  ice cream. most personalized ice cream. journe...  \n",
       "\n",
       "[6781 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd = pd.read_csv('/ceph/dpandya/notsofar/train_set/240825.1_train/new_segmented_audios/new_segmented_audios.csv')\n",
    "dd.dropna(subset=['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b142f81d",
   "metadata": {},
   "source": [
    "- randomly select a single-channel audio stream from the meetings\n",
    "- compile a list of these meetings\n",
    "- create a df with their transcription files\n",
    "- Divide them into train and eval sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31661da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir =  '/ceph/dpandya/notsofar/train_set/240825.1_train/MTG/'\n",
    "eval_dir = '/ceph/dpandya/notsofar/eval_set/240825.1_eval_full_with_GT/MTG/'\n",
    "train_meetings = os.listdir('/ceph/dpandya/notsofar/train_set/240825.1_train/MTG/')\n",
    "eval_meetings = os.listdir('/ceph/dpandya/notsofar/eval_set/240825.1_eval_full_with_GT/MTG/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3f65841d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = []\n",
    "transcription_files = []\n",
    "mic = []\n",
    "# Iterate through all the train meeting dir and choosing a random single channel audio stream\n",
    "for meet in train_meetings:\n",
    "    stream_list = []\n",
    "    # Collecting all the streams for a meeting\n",
    "    for stream in os.listdir(os.path.join(train_dir, meet)):\n",
    "        if os.path.isdir(os.path.join(train_dir, meet, stream)):\n",
    "            if stream.split('_')[0] == 'sc':\n",
    "                stream_list.append(os.path.join(train_dir, meet, stream, 'ch0.wav'))\n",
    "    random_ = random.choice(stream_list)\n",
    "    \n",
    "    mic.append(random_.split('/')[-2])\n",
    "    train_files.append(random_)\n",
    "    transcription_files.append(os.path.join(train_dir, meet, 'gt_transcription.json'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2ede91d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the same process for the eval files, choosing a random single channel audio stream\n",
    "eval_files = []\n",
    "eval_trans = []\n",
    "eval_mic = []\n",
    "# Iterate through all the eval meeting dir and choosing a random single channel audio stream\n",
    "for meet in eval_meetings:\n",
    "    stream_list = []\n",
    "    # Collecting all the streams for a meeting\n",
    "    if os.path.isdir(os.path.join(eval_dir, meet)):\n",
    "        for stream in os.listdir(os.path.join(eval_dir, meet)):\n",
    "            if os.path.isdir(os.path.join(eval_dir, meet, stream)):\n",
    "                if stream.split('_')[0] == 'sc':\n",
    "                    stream_list.append(os.path.join(eval_dir, meet, stream, 'ch0.wav'))\n",
    "        random_ = random.choice(stream_list)\n",
    "    \n",
    "        eval_mic.append(random_.split('/')[-2])\n",
    "        eval_files.append(random_)\n",
    "        eval_trans.append(os.path.join(eval_dir, meet, 'gt_transcription.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "69b3a0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame()\n",
    "train_df['audio_files'] = train_files\n",
    "train_df['transcription_file'] = transcription_files\n",
    "train_df['mic'] = mic\n",
    "\n",
    "test_df = pd.DataFrame()\n",
    "test_df['audio_files'] = eval_files\n",
    "test_df['transcription_files'] = eval_trans\n",
    "test_df['mic'] = eval_mic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c7559661",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('/ceph/dpandya/notsofar/newNotsofar/train.csv', index=False)\n",
    "test_df.to_csv('/ceph/dpandya/notsofar/newNotsofar/test.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "onlyWhisper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

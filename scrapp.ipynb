{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0c79b7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/dpandya/miniconda3/envs/onlyWhisper/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import librosa\n",
    "import transformers\n",
    "import adapters\n",
    "import huggingface_hub as hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "facc7ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['okay so we got a big budget in the office regarding snacks oh great yeah oh we got snacks or lunch and snacks no regarding snacks snacks okay and i know all of us and other people in the office i just called you guys but theres also other people in the office that have different preferences for foods that have food restrictions', 'so even though we have a big budget we want to make the most out of it so is there something that you guys would prefer to have or not to have in the office a big budget means the quantity we can buy or the quality the quality quality i dont go for quality im nuts about nuts so if were talking about quality were talking about pistachios pecans and cashews', 'isnt that kind of a waste of money like who eats that waste of money we have budget though yeah but who eats it oh i do healthy people thats right theyre the best snacks theyre not healthy look we want healthy but we want healthy i dont really eat healthy like i dont care for healthy snacks you dont care for healthy no like i think its kind of a waste of money alright so what are you looking for i think we should have like ice cream ice cream is not a snack']\n"
     ]
    }
   ],
   "source": [
    "print(list(pd.read_csv('/ceph/dpandya/notsofar/nsfd_adap_segments/baseline_large.csv')[\"preds_medium\"][0:3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d7606a",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "adapter_config should be an instance of PeftConfig. Got <class 'adapters.configuration.adapter_config.SeqBnConfig'> instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m small \u001b[38;5;241m=\u001b[39m transformers\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mwhisper\u001b[38;5;241m.\u001b[39mmodeling_whisper\u001b[38;5;241m.\u001b[39mWhisperPreTrainedModel\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopenai/whisper-small\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m seq \u001b[38;5;241m=\u001b[39m adapters\u001b[38;5;241m.\u001b[39mSeqBnConfig()\n\u001b[0;32m----> 4\u001b[0m \u001b[43msmall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_adapter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseq\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/work/dpandya/miniconda3/envs/onlyWhisper/lib/python3.11/site-packages/transformers/integrations/peft.py:311\u001b[0m, in \u001b[0;36mPeftAdapterMixin.add_adapter\u001b[0;34m(self, adapter_config, adapter_name)\u001b[0m\n\u001b[1;32m    308\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAdapter with name \u001b[39m\u001b[38;5;132;01m{\u001b[39;00madapter_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m already exists. Please use a different name.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(adapter_config, PeftConfig):\n\u001b[0;32m--> 311\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madapter_config should be an instance of PeftConfig. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(adapter_config)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    313\u001b[0m \u001b[38;5;66;03m# Retrieve the name or path of the model, one could also use self.config._name_or_path\u001b[39;00m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;66;03m# but to be consistent with what we do in PEFT: https://github.com/huggingface/peft/blob/6e783780ca9df3a623992cc4d1d665001232eae0/src/peft/mapping.py#L100\u001b[39;00m\n\u001b[1;32m    315\u001b[0m adapter_config\u001b[38;5;241m.\u001b[39mbase_model_name_or_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname_or_path\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[0;31mTypeError\u001b[0m: adapter_config should be an instance of PeftConfig. Got <class 'adapters.configuration.adapter_config.SeqBnConfig'> instead."
     ]
    }
   ],
   "source": [
    "small = transformers.models.whisper.modeling_whisper.WhisperPreTrainedModel.from_pretrained('openai/whisper-small')\n",
    "\n",
    "seq = adapters.SeqBnConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f91e973",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e077467",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = adapters.WhisperAdapterModel.from_pretrained('openai/whisper-medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21dc8e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.freeze_encoder()\n",
    "#adap_config = adapters\n",
    "model.add_adapter(adapter_name='sample', config=adapters.SeqBnConfig())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32c4b1a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WhisperAdapterModel(\n",
       "  (model): WhisperModel(\n",
       "    (encoder): WhisperEncoder(\n",
       "      (conv1): Conv1d(80, 1024, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (conv2): Conv1d(1024, 1024, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "      (embed_positions): Embedding(1500, 1024)\n",
       "      (layers): ModuleList(\n",
       "        (0-23): 24 x WhisperEncoderLayerWithAdapters(\n",
       "          (self_attn): WhisperSdpaAttentionWithAdapters(\n",
       "            (k_proj): LoRALinearTorch(\n",
       "              in_features=1024, out_features=1024, bias=False\n",
       "              (shared_parameters): ModuleDict()\n",
       "              (loras): ModuleDict()\n",
       "            )\n",
       "            (v_proj): LoRALinearTorch(\n",
       "              in_features=1024, out_features=1024, bias=True\n",
       "              (shared_parameters): ModuleDict()\n",
       "              (loras): ModuleDict()\n",
       "            )\n",
       "            (q_proj): LoRALinearTorch(\n",
       "              in_features=1024, out_features=1024, bias=True\n",
       "              (shared_parameters): ModuleDict()\n",
       "              (loras): ModuleDict()\n",
       "            )\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (prefix_tuning): PrefixTuningLayer(\n",
       "              (prefix_gates): ModuleDict()\n",
       "              (pool): PrefixTuningPool(\n",
       "                (prefix_tunings): ModuleDict()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): LoRALinearTorch(\n",
       "            in_features=1024, out_features=4096, bias=True\n",
       "            (shared_parameters): ModuleDict()\n",
       "            (loras): ModuleDict()\n",
       "          )\n",
       "          (fc2): LoRALinearTorch(\n",
       "            in_features=4096, out_features=1024, bias=True\n",
       "            (shared_parameters): ModuleDict()\n",
       "            (loras): ModuleDict()\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (reft_layer): ReftLayer(\n",
       "            (refts): ModuleDict()\n",
       "          )\n",
       "          (attention_adapters): BottleneckLayer(\n",
       "            (adapters): ModuleDict()\n",
       "            (adapter_fusion_layer): ModuleDict()\n",
       "          )\n",
       "          (output_adapters): BottleneckLayer(\n",
       "            (adapters): ModuleDict(\n",
       "              (sample): Adapter(\n",
       "                (non_linearity): Activation_Function_Class(\n",
       "                  (f): ReLU()\n",
       "                )\n",
       "                (adapter_down): Sequential(\n",
       "                  (0): Linear(in_features=1024, out_features=64, bias=True)\n",
       "                  (1): Activation_Function_Class(\n",
       "                    (f): ReLU()\n",
       "                  )\n",
       "                )\n",
       "                (adapter_up): Linear(in_features=64, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (adapter_fusion_layer): ModuleDict()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (invertible_adapters): ModuleDict()\n",
       "    )\n",
       "    (decoder): WhisperDecoder(\n",
       "      (embed_tokens): Embedding(51865, 1024, padding_idx=50257)\n",
       "      (embed_positions): WhisperPositionalEmbedding(448, 1024)\n",
       "      (layers): ModuleList(\n",
       "        (0-23): 24 x WhisperDecoderLayerWithAdapters(\n",
       "          (self_attn): WhisperSdpaAttentionWithAdapters(\n",
       "            (k_proj): LoRALinearTorch(\n",
       "              in_features=1024, out_features=1024, bias=False\n",
       "              (shared_parameters): ModuleDict()\n",
       "              (loras): ModuleDict()\n",
       "            )\n",
       "            (v_proj): LoRALinearTorch(\n",
       "              in_features=1024, out_features=1024, bias=True\n",
       "              (shared_parameters): ModuleDict()\n",
       "              (loras): ModuleDict()\n",
       "            )\n",
       "            (q_proj): LoRALinearTorch(\n",
       "              in_features=1024, out_features=1024, bias=True\n",
       "              (shared_parameters): ModuleDict()\n",
       "              (loras): ModuleDict()\n",
       "            )\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (prefix_tuning): PrefixTuningLayer(\n",
       "              (prefix_gates): ModuleDict()\n",
       "              (pool): PrefixTuningPool(\n",
       "                (prefix_tunings): ModuleDict()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): WhisperSdpaAttentionWithAdapters(\n",
       "            (k_proj): LoRALinearTorch(\n",
       "              in_features=1024, out_features=1024, bias=False\n",
       "              (shared_parameters): ModuleDict()\n",
       "              (loras): ModuleDict()\n",
       "            )\n",
       "            (v_proj): LoRALinearTorch(\n",
       "              in_features=1024, out_features=1024, bias=True\n",
       "              (shared_parameters): ModuleDict()\n",
       "              (loras): ModuleDict()\n",
       "            )\n",
       "            (q_proj): LoRALinearTorch(\n",
       "              in_features=1024, out_features=1024, bias=True\n",
       "              (shared_parameters): ModuleDict()\n",
       "              (loras): ModuleDict()\n",
       "            )\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (prefix_tuning): PrefixTuningLayer(\n",
       "              (prefix_gates): ModuleDict()\n",
       "              (pool): PrefixTuningPool(\n",
       "                (prefix_tunings): ModuleDict()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): LoRALinearTorch(\n",
       "            in_features=1024, out_features=4096, bias=True\n",
       "            (shared_parameters): ModuleDict()\n",
       "            (loras): ModuleDict()\n",
       "          )\n",
       "          (fc2): LoRALinearTorch(\n",
       "            in_features=4096, out_features=1024, bias=True\n",
       "            (shared_parameters): ModuleDict()\n",
       "            (loras): ModuleDict()\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (reft_layer): ReftLayer(\n",
       "            (refts): ModuleDict()\n",
       "          )\n",
       "          (attention_adapters): BottleneckLayer(\n",
       "            (adapters): ModuleDict()\n",
       "            (adapter_fusion_layer): ModuleDict()\n",
       "          )\n",
       "          (output_adapters): BottleneckLayer(\n",
       "            (adapters): ModuleDict(\n",
       "              (sample): Adapter(\n",
       "                (non_linearity): Activation_Function_Class(\n",
       "                  (f): ReLU()\n",
       "                )\n",
       "                (adapter_down): Sequential(\n",
       "                  (0): Linear(in_features=1024, out_features=64, bias=True)\n",
       "                  (1): Activation_Function_Class(\n",
       "                    (f): ReLU()\n",
       "                  )\n",
       "                )\n",
       "                (adapter_up): Linear(in_features=64, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (adapter_fusion_layer): ModuleDict()\n",
       "          )\n",
       "          (cross_attention_adapters): BottleneckLayer(\n",
       "            (adapters): ModuleDict()\n",
       "            (adapter_fusion_layer): ModuleDict()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (shared_parameters): ModuleDict()\n",
       "    (prefix_tuning): PrefixTuningPool(\n",
       "      (prefix_tunings): ModuleDict()\n",
       "    )\n",
       "  )\n",
       "  (heads): ModuleDict(\n",
       "    (default): Seq2SeqLMHead(\n",
       "      (0): Linear(in_features=1024, out_features=51865, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "377eb22d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-03 15:22:09.285748: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-11-03 15:22:09.285817: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-11-03 15:22:09.293426: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-11-03 15:22:09.349322: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-03 15:22:11.583895: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "model = transformers.WhisperForConditionalGeneration.from_pretrained(\n",
    "    'openai/whisper-medium',\n",
    "    dtype=torch.float16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d15d76c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.max_length=512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e8edd77",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'url_to_filename' from 'huggingface_hub.file_download' (/work/dpandya/miniconda3/envs/onlyWhisper/lib/python3.11/site-packages/huggingface_hub/file_download.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m m2 \u001b[38;5;241m=\u001b[39m \u001b[43madapters\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mWhisperAdapterModel\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopenai/whisper-medium\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#model.freeze_encoder()\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#model.add_adapter('test', 'seqBN')\u001b[39;00m\n",
      "File \u001b[0;32m/work/dpandya/miniconda3/envs/onlyWhisper/lib/python3.11/site-packages/transformers/utils/import_utils.py:2302\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2300\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module:\n\u001b[1;32m   2301\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2302\u001b[0m         module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_class_to_module\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2303\u001b[0m         value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[1;32m   2304\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mRuntimeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/work/dpandya/miniconda3/envs/onlyWhisper/lib/python3.11/site-packages/transformers/utils/import_utils.py:2332\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   2330\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m   2331\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 2332\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m/work/dpandya/miniconda3/envs/onlyWhisper/lib/python3.11/site-packages/transformers/utils/import_utils.py:2330\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   2328\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_module\u001b[39m(\u001b[38;5;28mself\u001b[39m, module_name: \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m   2329\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2330\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2331\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   2332\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m/work/dpandya/miniconda3/envs/onlyWhisper/lib/python3.11/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1204\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1176\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1126\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1204\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1176\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1147\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:690\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:940\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m/work/dpandya/miniconda3/envs/onlyWhisper/lib/python3.11/site-packages/adapters/models/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01malbert\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmixin_albert\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AlbertModelAdaptersMixin\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbart\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmixin_bart\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      3\u001b[0m     BartDecoderAdaptersMixin,\n\u001b[1;32m      4\u001b[0m     BartDecoderWrapperAdaptersMixin,\n\u001b[1;32m      5\u001b[0m     BartEncoderAdaptersMixin,\n\u001b[1;32m      6\u001b[0m     BartModelAdaptersMixin,\n\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbeit\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmixin_beit\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BeitIntermediateAdaptersMixin, BeitModelAdaptersMixin, BeitOutputAdaptersMixin\n",
      "File \u001b[0;32m/work/dpandya/miniconda3/envs/onlyWhisper/lib/python3.11/site-packages/adapters/models/albert/mixin_albert.py:6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcomposition\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m adjust_tensors_for_parallel_\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmethods\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbottleneck\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BottleneckLayer\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmethods\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlora\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LoRALinear\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmethods\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprefix_tuning\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PrefixTuningLayer\n",
      "File \u001b[0;32m/work/dpandya/miniconda3/envs/onlyWhisper/lib/python3.11/site-packages/adapters/methods/bottleneck.py:16\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nn\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcomposition\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      7\u001b[0m     AdapterCompositionBlock,\n\u001b[1;32m      8\u001b[0m     Average,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m     adjust_tensors_for_parallel,\n\u001b[1;32m     15\u001b[0m )\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfiguration\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BnConfig\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ForwardContext\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01madapter_layer_base\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ComposableAdapterLayerBase\n",
      "File \u001b[0;32m/work/dpandya/miniconda3/envs/onlyWhisper/lib/python3.11/site-packages/adapters/configuration/__init__.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# flake8: noqa\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01madapter_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01madapter_fusion_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_adapters_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ModelAdaptersConfig, build_full_config\n",
      "File \u001b[0;32m/work/dpandya/miniconda3/envs/onlyWhisper/lib/python3.11/site-packages/adapters/configuration/adapter_config.py:6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdataclasses\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FrozenInstanceError, asdict, dataclass, field, replace\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m List, Literal, Optional, Union\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m resolve_adapter_config\n\u001b[1;32m      9\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mAdapterConfig\u001b[39;00m(Mapping):\n",
      "File \u001b[0;32m/work/dpandya/miniconda3/envs/onlyWhisper/lib/python3.11/site-packages/adapters/utils.py:28\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfilelock\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FileLock\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhuggingface_hub\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HfApi, HfFolder, snapshot_download\n\u001b[0;32m---> 28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhuggingface_hub\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfile_download\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m http_get, url_to_filename\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhuggingface_hub\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     30\u001b[0m     EntryNotFoundError,\n\u001b[1;32m     31\u001b[0m     RepositoryNotFoundError,\n\u001b[1;32m     32\u001b[0m     RevisionNotFoundError,\n\u001b[1;32m     33\u001b[0m     hf_raise_for_status,\n\u001b[1;32m     34\u001b[0m )\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTTPError\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'url_to_filename' from 'huggingface_hub.file_download' (/work/dpandya/miniconda3/envs/onlyWhisper/lib/python3.11/site-packages/huggingface_hub/file_download.py)"
     ]
    }
   ],
   "source": [
    "m2 = adapters.WhisperAdapterModel('openai/whisper-medium')\n",
    "\n",
    "#model.freeze_encoder()\n",
    "#model.add_adapter('test', 'seqBN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb6a3d7a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'url_to_filename' from 'huggingface_hub.file_download' (/work/dpandya/miniconda3/envs/onlyWhisper/lib/python3.11/site-packages/huggingface_hub/file_download.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43madapters\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mWhisperAdapterModel\u001b[49m\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopenai/whisper-large-v3\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/work/dpandya/miniconda3/envs/onlyWhisper/lib/python3.11/site-packages/transformers/utils/import_utils.py:2302\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2300\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module:\n\u001b[1;32m   2301\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2302\u001b[0m         module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_class_to_module\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2303\u001b[0m         value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[1;32m   2304\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mRuntimeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/work/dpandya/miniconda3/envs/onlyWhisper/lib/python3.11/site-packages/transformers/utils/import_utils.py:2332\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   2330\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m   2331\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 2332\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m/work/dpandya/miniconda3/envs/onlyWhisper/lib/python3.11/site-packages/transformers/utils/import_utils.py:2330\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   2328\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_module\u001b[39m(\u001b[38;5;28mself\u001b[39m, module_name: \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m   2329\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2330\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2331\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   2332\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m/work/dpandya/miniconda3/envs/onlyWhisper/lib/python3.11/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1204\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1176\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1126\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1204\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1176\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1147\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:690\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:940\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m/work/dpandya/miniconda3/envs/onlyWhisper/lib/python3.11/site-packages/adapters/models/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01malbert\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmixin_albert\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AlbertModelAdaptersMixin\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbart\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmixin_bart\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      3\u001b[0m     BartDecoderAdaptersMixin,\n\u001b[1;32m      4\u001b[0m     BartDecoderWrapperAdaptersMixin,\n\u001b[1;32m      5\u001b[0m     BartEncoderAdaptersMixin,\n\u001b[1;32m      6\u001b[0m     BartModelAdaptersMixin,\n\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbeit\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmixin_beit\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BeitIntermediateAdaptersMixin, BeitModelAdaptersMixin, BeitOutputAdaptersMixin\n",
      "File \u001b[0;32m/work/dpandya/miniconda3/envs/onlyWhisper/lib/python3.11/site-packages/adapters/models/albert/mixin_albert.py:6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcomposition\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m adjust_tensors_for_parallel_\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmethods\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbottleneck\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BottleneckLayer\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmethods\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlora\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LoRALinear\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmethods\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprefix_tuning\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PrefixTuningLayer\n",
      "File \u001b[0;32m/work/dpandya/miniconda3/envs/onlyWhisper/lib/python3.11/site-packages/adapters/methods/bottleneck.py:16\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nn\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcomposition\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      7\u001b[0m     AdapterCompositionBlock,\n\u001b[1;32m      8\u001b[0m     Average,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m     adjust_tensors_for_parallel,\n\u001b[1;32m     15\u001b[0m )\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfiguration\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BnConfig\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ForwardContext\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01madapter_layer_base\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ComposableAdapterLayerBase\n",
      "File \u001b[0;32m/work/dpandya/miniconda3/envs/onlyWhisper/lib/python3.11/site-packages/adapters/configuration/__init__.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# flake8: noqa\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01madapter_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01madapter_fusion_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_adapters_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ModelAdaptersConfig, build_full_config\n",
      "File \u001b[0;32m/work/dpandya/miniconda3/envs/onlyWhisper/lib/python3.11/site-packages/adapters/configuration/adapter_config.py:6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdataclasses\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FrozenInstanceError, asdict, dataclass, field, replace\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m List, Literal, Optional, Union\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m resolve_adapter_config\n\u001b[1;32m      9\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mAdapterConfig\u001b[39;00m(Mapping):\n",
      "File \u001b[0;32m/work/dpandya/miniconda3/envs/onlyWhisper/lib/python3.11/site-packages/adapters/utils.py:28\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfilelock\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FileLock\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhuggingface_hub\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HfApi, HfFolder, snapshot_download\n\u001b[0;32m---> 28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhuggingface_hub\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfile_download\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m http_get, url_to_filename\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhuggingface_hub\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     30\u001b[0m     EntryNotFoundError,\n\u001b[1;32m     31\u001b[0m     RepositoryNotFoundError,\n\u001b[1;32m     32\u001b[0m     RevisionNotFoundError,\n\u001b[1;32m     33\u001b[0m     hf_raise_for_status,\n\u001b[1;32m     34\u001b[0m )\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTTPError\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'url_to_filename' from 'huggingface_hub.file_download' (/work/dpandya/miniconda3/envs/onlyWhisper/lib/python3.11/site-packages/huggingface_hub/file_download.py)"
     ]
    }
   ],
   "source": [
    "adapters.WhisperAdapterModel.from_pretrained('openai/whisper-large-v3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f740b613",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('/ceph/dpandya/notsofar/nsfd_adap_segments/train_segments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1995aeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_audio_file</th>\n",
       "      <th>segmented_audio_file</th>\n",
       "      <th>segmented_text</th>\n",
       "      <th>start</th>\n",
       "      <th>stop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>MTG_31035_ch0_segment_1.wav</td>\n",
       "      <td>Alright everyone let us continue on with our d...</td>\n",
       "      <td>4960.0</td>\n",
       "      <td>28610.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>MTG_31035_ch0_segment_2.wav</td>\n",
       "      <td>I'm &lt;ISSUE/&gt; yet to use it 'cause I was meanin...</td>\n",
       "      <td>29210.0</td>\n",
       "      <td>50010.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>MTG_31035_ch0_segment_3.wav</td>\n",
       "      <td>&lt;ST/&gt; we do have people come but like it is me...</td>\n",
       "      <td>50110.0</td>\n",
       "      <td>74380.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>MTG_31035_ch0_segment_4.wav</td>\n",
       "      <td>&lt;ST/&gt; who is already asleep yeah. Mmm. Oh I se...</td>\n",
       "      <td>74610.0</td>\n",
       "      <td>98590.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>MTG_31035_ch0_segment_5.wav</td>\n",
       "      <td>&lt;ST/&gt; um people who &lt;ST/&gt; who have trouble sle...</td>\n",
       "      <td>99110.0</td>\n",
       "      <td>119060.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1143</th>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>MTG_30983_ch0_segment_12.wav</td>\n",
       "      <td>We should have both I think. Yes. Outdoor uh &lt;...</td>\n",
       "      <td>251280.0</td>\n",
       "      <td>271550.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1144</th>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>MTG_30983_ch0_segment_13.wav</td>\n",
       "      <td>&lt;ST/&gt; there could be um like toys and things f...</td>\n",
       "      <td>271650.0</td>\n",
       "      <td>294530.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1145</th>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>MTG_30983_ch0_segment_14.wav</td>\n",
       "      <td>&lt;ST/&gt; perpendicular to that? So like on top is...</td>\n",
       "      <td>295000.0</td>\n",
       "      <td>319370.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1146</th>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>MTG_30983_ch0_segment_15.wav</td>\n",
       "      <td>That's a &lt;ST/&gt; A journey to the best &lt;ST/&gt; &lt;ST...</td>\n",
       "      <td>320010.0</td>\n",
       "      <td>341820.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1147</th>\n",
       "      <td>/ceph/dpandya/notsofar/train_set/240825.1_trai...</td>\n",
       "      <td>MTG_30983_ch0_segment_16.wav</td>\n",
       "      <td>Do we only have like the same flavors or are w...</td>\n",
       "      <td>358980.0</td>\n",
       "      <td>359520.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1148 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    original_audio_file  \\\n",
       "0     /ceph/dpandya/notsofar/train_set/240825.1_trai...   \n",
       "1     /ceph/dpandya/notsofar/train_set/240825.1_trai...   \n",
       "2     /ceph/dpandya/notsofar/train_set/240825.1_trai...   \n",
       "3     /ceph/dpandya/notsofar/train_set/240825.1_trai...   \n",
       "4     /ceph/dpandya/notsofar/train_set/240825.1_trai...   \n",
       "...                                                 ...   \n",
       "1143  /ceph/dpandya/notsofar/train_set/240825.1_trai...   \n",
       "1144  /ceph/dpandya/notsofar/train_set/240825.1_trai...   \n",
       "1145  /ceph/dpandya/notsofar/train_set/240825.1_trai...   \n",
       "1146  /ceph/dpandya/notsofar/train_set/240825.1_trai...   \n",
       "1147  /ceph/dpandya/notsofar/train_set/240825.1_trai...   \n",
       "\n",
       "              segmented_audio_file  \\\n",
       "0      MTG_31035_ch0_segment_1.wav   \n",
       "1      MTG_31035_ch0_segment_2.wav   \n",
       "2      MTG_31035_ch0_segment_3.wav   \n",
       "3      MTG_31035_ch0_segment_4.wav   \n",
       "4      MTG_31035_ch0_segment_5.wav   \n",
       "...                            ...   \n",
       "1143  MTG_30983_ch0_segment_12.wav   \n",
       "1144  MTG_30983_ch0_segment_13.wav   \n",
       "1145  MTG_30983_ch0_segment_14.wav   \n",
       "1146  MTG_30983_ch0_segment_15.wav   \n",
       "1147  MTG_30983_ch0_segment_16.wav   \n",
       "\n",
       "                                         segmented_text     start      stop  \n",
       "0     Alright everyone let us continue on with our d...    4960.0   28610.0  \n",
       "1     I'm <ISSUE/> yet to use it 'cause I was meanin...   29210.0   50010.0  \n",
       "2     <ST/> we do have people come but like it is me...   50110.0   74380.0  \n",
       "3     <ST/> who is already asleep yeah. Mmm. Oh I se...   74610.0   98590.0  \n",
       "4     <ST/> um people who <ST/> who have trouble sle...   99110.0  119060.0  \n",
       "...                                                 ...       ...       ...  \n",
       "1143  We should have both I think. Yes. Outdoor uh <...  251280.0  271550.0  \n",
       "1144  <ST/> there could be um like toys and things f...  271650.0  294530.0  \n",
       "1145  <ST/> perpendicular to that? So like on top is...  295000.0  319370.0  \n",
       "1146  That's a <ST/> A journey to the best <ST/> <ST...  320010.0  341820.0  \n",
       "1147  Do we only have like the same flavors or are w...  358980.0  359520.0  \n",
       "\n",
       "[1148 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('/ceph/dpandya/notsofar/nsfd_adap_segments/train_segments.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "onlyWhisper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

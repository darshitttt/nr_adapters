{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "69d53e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pydub import AudioSegment\n",
    "from tqdm import tqdm\n",
    "\n",
    "eval_df = pd.read_csv('/ceph/dpandya/notsofar/eval_set/240825.1_eval_full_with_GT/MTG/eval.csv')\n",
    "train_df = pd.read_csv('/ceph/dpandya/notsofar/train_set/240825.1_train/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bbc067db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_multiple_audios(audio_files, csv_files, output_dir, output_csv, min_duration=10, max_duration=25):\n",
    "    # Ensure output directory exists\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Initialize the final DataFrame for all metadata\n",
    "    all_segments = []\n",
    "\n",
    "    # Process each audio and its corresponding CSV file\n",
    "    for audio_file, csv_file in zip(audio_files, csv_files):\n",
    "        # Load the audio file\n",
    "        audio = AudioSegment.from_file(audio_file)\n",
    "\n",
    "        # Load the CSV file\n",
    "        df = pd.read_json(csv_file).sort_values(by='start_time', ascending=True)\n",
    "\n",
    "        meeting = csv_file.split('/')[-2]\n",
    "\n",
    "        # Initialize variables\n",
    "        segments = []\n",
    "        current_text = \"\"\n",
    "        current_start = None\n",
    "        segment_start = None\n",
    "        segment_stop = None\n",
    "        segment_duration = 0\n",
    "\n",
    "        # Iterate through the rows of the CSV\n",
    "        for _, row in df.iterrows():\n",
    "            start = row['start_time'] * 1000  # Convert to milliseconds\n",
    "            stop = row['end_time'] * 1000   # Convert to milliseconds\n",
    "            text = row['text']\n",
    "            duration = stop - start\n",
    "            #print(duration/1000, start/1000, stop/1000)\n",
    "            if current_start is None:\n",
    "                # Initialize the first segment\n",
    "                current_start = start\n",
    "                segment_start = start\n",
    "                current_text = text\n",
    "                segment_duration = duration\n",
    "            else:\n",
    "                # Check if adding this segment keeps duration within limits\n",
    "                if (stop - segment_start) <= max_duration * 1000:\n",
    "                    segment_duration += duration\n",
    "                    segment_stop = stop\n",
    "                    current_text += \" \" + text\n",
    "                else:\n",
    "                    # Finalize the current segment\n",
    "                    segments.append((segment_start, segment_stop))\n",
    "                    all_segments.append({\n",
    "                        \"original_audio_file\": (audio_file),\n",
    "                        \"segmented_audio_file\": f\"{meeting}_{os.path.splitext(os.path.basename(audio_file))[0]}_segment_{len(segments)}.wav\",\n",
    "                        \"segmented_text\": current_text.strip(),\n",
    "                        \"start\": segment_start,\n",
    "                        \"stop\": segment_stop\n",
    "                    })\n",
    "\n",
    "                    # Start a new segment\n",
    "                    current_start = start\n",
    "                    segment_start = start\n",
    "                    segment_stop = stop\n",
    "                    current_text = text\n",
    "                    segment_duration = duration\n",
    "\n",
    "                # If segment is too short, combine it\n",
    "                if segment_duration < min_duration * 1000:\n",
    "                    continue\n",
    "            #print(segments)\n",
    "\n",
    "        # Save the last segment if it hasn't been added\n",
    "        if segment_duration >= min_duration * 1000:\n",
    "            segments.append((segment_start, segment_stop))\n",
    "            all_segments.append({\n",
    "                \"original_audio_file\": (audio_file),\n",
    "                \"segmented_audio_file\": f\"{meeting}_{os.path.splitext(os.path.basename(audio_file))[0]}_segment_{len(segments)}.wav\",\n",
    "                \"segmented_text\": current_text.strip(),\n",
    "                \"start\": start,\n",
    "                \"stop\": stop\n",
    "            })\n",
    "\n",
    "        # Save the audio segments\n",
    "        for i, (start, stop) in enumerate(segments):\n",
    "            segment_filename = all_segments[-len(segments) + i]['segmented_audio_file']\n",
    "            segment = audio[start:stop]\n",
    "            segment.export(os.path.join(output_dir, segment_filename), format=\"wav\")\n",
    "\n",
    "    # Save the consolidated CSV file\n",
    "    final_df = pd.DataFrame(all_segments)\n",
    "    final_df.to_csv(output_csv, index=False)\n",
    "\n",
    "    print(f\"Processed {len(all_segments)} segments across all files.\")\n",
    "    print(f\"All segments saved in: {output_dir}\")\n",
    "    print(f\"Consolidated metadata saved in: {output_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "311e271d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "transcript_files = list(train_df['gt_transcription_files'].unique())\n",
    "audio_files = []\n",
    "\n",
    "for gtFile in transcript_files:\n",
    "    audio_files.append(random.choice(list(train_df[train_df['gt_transcription_files']==gtFile]['sc_files'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c95638d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1148 segments across all files.\n",
      "All segments saved in: /ceph/dpandya/notsofar/nsfd_adap_segments/train/\n",
      "Consolidated metadata saved in: /ceph/dpandya/notsofar/nsfd_adap_segments/train_segments.csv\n"
     ]
    }
   ],
   "source": [
    "segment_multiple_audios(\n",
    "    audio_files,\n",
    "    transcript_files,\n",
    "    '/ceph/dpandya/notsofar/nsfd_adap_segments/train/',\n",
    "    '/ceph/dpandya/notsofar/nsfd_adap_segments/train_segments.csv'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "onlyWhisper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
